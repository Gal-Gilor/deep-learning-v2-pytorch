{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "\n",
    "In this project, you'll generate your own [Seinfeld](https://en.wikipedia.org/wiki/Seinfeld) TV scripts using RNNs.  You'll be using part of the [Seinfeld dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv) of scripts from 9 seasons.  The Neural Network you'll build will generate a new ,\"fake\" TV script, based on patterns it recognizes in this training data.\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "The data is already provided for you in `./data/Seinfeld_Scripts.txt` and you're encouraged to open that file and look at the text. \n",
    ">* As a first step, we'll load in this data and look at some samples. \n",
    "* Then, you'll be tasked with defining and training an RNN to generate a new script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# load in data\n",
    "import helper\n",
    "data_dir = './data/Seinfeld_Scripts.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_line_range` to view different parts of the data. This will give you a sense of the data you'll be working with. You can see, for example, that it is all lowercase text, and each new line of dialogue is separated by a newline character `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
      "\n",
      "george: are you through? \n",
      "\n",
      "jerry: you do of course try on, when you buy? \n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implement Pre-processing Functions\n",
    "The first thing to do to any dataset is pre-processing.  Implement the following pre-processing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following **tuple** `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "import collections\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # Count and sort the corpus\n",
    "    word_counts = collections.Counter(text)\n",
    "    sorted_counts = word_counts.most_common()\n",
    "    \n",
    "    # create the look up dictionaries\n",
    "    int_to_vocab = {n: word_tuple[0] for n, word_tuple in enumerate(sorted_counts)}\n",
    "    vocab_to_int = {word: n for n, word in int_to_vocab.items()}\n",
    "\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, \"bye\" and \"bye!\" would generate two different word ids.\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( **.** )\n",
    "- Comma ( **,** )\n",
    "- Quotation Mark ( **\"** )\n",
    "- Semicolon ( **;** )\n",
    "- Exclamation mark ( **!** )\n",
    "- Question mark ( **?** )\n",
    "- Left Parentheses ( **(** )\n",
    "- Right Parentheses ( **)** )\n",
    "- Dash ( **-** )\n",
    "- Return ( **\\n** )\n",
    "\n",
    "This dictionary will be used to tokenize the symbols and add the delimiter (space) around it.  This separates each symbols as its own word, making it easier for the neural network to predict the next word. Make sure you don't use a value that could be confused as a word; for example, instead of using the value \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    return {\n",
    "        '.': '||period||',\n",
    "        ',': '||come||',\n",
    "        '\"': '||doublequote||',\n",
    "        ';': '||semicolon||',\n",
    "        '!': '||exclamation||',\n",
    "        '?': '||questionmark||',\n",
    "        '(': '||lparenth||',\n",
    "        ')': '||rparenth||',\n",
    "        '-': '||dash||',\n",
    "        '\\n': '||newline||'\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process all the data and save it\n",
    "\n",
    "Running the code cell below will pre-process all the data and save it to file. You're encouraged to look at the code for `preprocess_and_save_data` in the `helpers.py` file to see what it's doing in detail, but you do not need to change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# pre-process training data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "from tqdm import tqdm\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "In this section, you'll build the components necessary to build an RNN by implementing the RNN Module and forward and backpropagation functions.\n",
    "\n",
    "### Check Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "Let's start with the preprocessed input data. We'll use [TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset) to provide a known format to our dataset; in combination with [DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader), it will handle batching, shuffling, and other dataset iteration functions.\n",
    "\n",
    "You can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.\n",
    "```\n",
    "data = TensorDataset(feature_tensors, target_tensors)\n",
    "data_loader = torch.utils.data.DataLoader(data, \n",
    "                                          batch_size=batch_size)\n",
    "```\n",
    "\n",
    "### Batching\n",
    "Implement the `batch_data` function to batch `words` data into chunks of size `batch_size` using the `TensorDataset` and `DataLoader` classes.\n",
    "\n",
    ">You can batch words using the DataLoader, but it will be up to you to create `feature_tensors` and `target_tensors` of the correct size and content for a given `sequence_length`.\n",
    "\n",
    "For example, say we have these as input:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "Your first `feature_tensor` should contain the values:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "And the corresponding `target_tensor` should just be the next \"word\"/tokenized word value:\n",
    "```\n",
    "5\n",
    "```\n",
    "This should continue with the second `feature_tensor`, `target_tensor` being:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"    \n",
    "    # get number of targets we can make (must create full sequences)\n",
    "    n_targets = len(words) - sequence_length\n",
    "\n",
    "    # create the targets and features\n",
    "    features, targets = [], []\n",
    "    for i in range(n_targets):\n",
    "        features.append(words[i : i+sequence_length])\n",
    "        targets.append(words[i+sequence_length])\n",
    "    \n",
    "    # convert Python list to PyTroch Tensors\n",
    "    features, targets = np.asarray(features), np.asarray(targets)\n",
    "    features, targets = torch.from_numpy(features), torch.from_numpy(targets)\n",
    "    \n",
    "    # instanciate PyTorch's dataset class and DataLoader\n",
    "    dataset = TensorDataset(features, targets)\n",
    "    dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your dataloader \n",
    "\n",
    "You'll have to modify this code to test a batching function, but it should look fairly similar.\n",
    "\n",
    "Below, we're generating some test text data and defining a dataloader using the function you defined, above. Then, we are getting some sample batch of inputs `sample_x` and targets `sample_y` from our dataloader.\n",
    "\n",
    "Your code should return something like the following (likely in a different order, if you shuffled your data):\n",
    "\n",
    "```\n",
    "torch.Size([10, 5])\n",
    "tensor([[ 28,  29,  30,  31,  32],\n",
    "        [ 21,  22,  23,  24,  25],\n",
    "        [ 17,  18,  19,  20,  21],\n",
    "        [ 34,  35,  36,  37,  38],\n",
    "        [ 11,  12,  13,  14,  15],\n",
    "        [ 23,  24,  25,  26,  27],\n",
    "        [  6,   7,   8,   9,  10],\n",
    "        [ 38,  39,  40,  41,  42],\n",
    "        [ 25,  26,  27,  28,  29],\n",
    "        [  7,   8,   9,  10,  11]])\n",
    "\n",
    "torch.Size([10])\n",
    "tensor([ 33,  26,  22,  39,  16,  28,  11,  43,  30,  12])\n",
    "```\n",
    "\n",
    "### Sizes\n",
    "Your sample_x should be of size `(batch_size, sequence_length)` or (10, 5) in this case and sample_y should just have one dimension: batch_size (10). \n",
    "\n",
    "### Values\n",
    "\n",
    "You should also notice that the targets, sample_y, are the *next* value in the ordered test_text data. So, for an input sequence `[ 28,  29,  30,  31,  32]` that ends with the value `32`, the corresponding output should be `33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "tensor([[41, 42, 43, 44, 45],\n",
      "        [43, 44, 45, 46, 47],\n",
      "        [ 8,  9, 10, 11, 12],\n",
      "        [27, 28, 29, 30, 31],\n",
      "        [38, 39, 40, 41, 42],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [ 3,  4,  5,  6,  7],\n",
      "        [37, 38, 39, 40, 41],\n",
      "        [29, 30, 31, 32, 33],\n",
      "        [20, 21, 22, 23, 24]], dtype=torch.int32)\n",
      "\n",
      "torch.Size([10])\n",
      "tensor([46, 48, 13, 32, 43, 10,  8, 42, 34, 25], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "\n",
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the Neural Network\n",
    "Implement an RNN using PyTorch's [Module class](http://pytorch.org/docs/master/nn.html#torch.nn.Module). You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:\n",
    " - `__init__` - The initialize function. \n",
    " - `init_hidden` - The initialization function for an LSTM/GRU hidden state\n",
    " - `forward` - Forward propagation function.\n",
    " \n",
    "The initialize function should create the layers of the neural network and save them to the class. The forward propagation function will use these layers to run forward propagation and generate an output and a hidden state.\n",
    "\n",
    "**The output of this model should be the *last* batch of word scores** after a complete sequence has been processed. That is, for each input sequence of words, we only want to output the word scores for a single, most likely, next word.\n",
    "\n",
    "### Hints\n",
    "\n",
    "1. Make sure to stack the outputs of the lstm to pass to your fully-connected layer, you can do this with `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`\n",
    "2. You can get the last batch of word scores by shaping the output of the final, fully-connected layer like so:\n",
    "\n",
    "```\n",
    "# reshape into (batch_size, seq_length, output_size)\n",
    "output = output.view(batch_size, -1, self.output_size)\n",
    "# get last batch\n",
    "out = output[:, -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # init hidden weights params\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # define the LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "\n",
    "        # define fully-connected layer\n",
    "        self.dense = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state        \n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"    \n",
    "        # ensure embedding layer gets a LongTensor input\n",
    "        nn_input = nn_input.long()\n",
    "        \n",
    "        # get the batch size for reshaping\n",
    "        batch_size = nn_input.size(0)\n",
    "        \n",
    "        ## define forward pass\n",
    "        embed = self.embedding(nn_input)\n",
    "        output, state = self.lstm(embed, hidden)\n",
    "        \n",
    "        # stack LSTM\n",
    "        output = output.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # pass through last fully connected layer\n",
    "        output = self.dense(output)\n",
    "        \n",
    "        output = output.view(batch_size, -1, self.vocab_size)\n",
    "        output = output[:, -1] # save only the last output\n",
    "        \n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return output, state   \n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (torch.cuda.is_available()): #\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_rnn(RNN, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define forward and backpropagation\n",
    "\n",
    "Use the RNN class you implemented to apply forward and back propagation. This function will be called, iteratively, in the training loop as follows:\n",
    "```\n",
    "loss = forward_back_prop(decoder, decoder_optimizer, criterion, inp, target)\n",
    "```\n",
    "\n",
    "And it should return the average loss over a batch and the hidden state returned by a call to `RNN(inp, hidden)`. Recall that you can get this loss by computing it, as usual, and calling `loss.item()`.\n",
    "\n",
    "**If a GPU is available, you should move your data to that GPU device, here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \"\"\"\n",
    "    Forward and backward propagation on the neural network\n",
    "    :param rnn: The PyTorch Module that holds the neural network\n",
    "    :param optimizer: The PyTorch optimizer for the neural network\n",
    "    :param criterion: The PyTorch loss function\n",
    "    :param inp: A batch of input to the neural network\n",
    "    :param target: The target output for the batch of input\n",
    "    :return: The loss and the latest hidden state Tensor\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # move data to GPU, if available\n",
    "    rnn.to(device)\n",
    "    inp, target = inp.to(device), target.to(device)\n",
    "    \n",
    "    # dismember the hidden states to prevent backprop through entire training history\n",
    "    hidden = tuple([hid.data for hid in hidden])\n",
    "    \n",
    "    # zero accumulated gradients\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    # get the output and hidden state from the model\n",
    "    output, hidden = rnn(inp, hidden)\n",
    "    \n",
    "    # calcualte the loss\n",
    "    loss = criterion(output.squeeze(), target.long())\n",
    "    \n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip to prevent gradients from becoming too large before optimizating\n",
    "    # nn.utils.clip_grad_norm_(rnn.parameters(), 4) # CLIPS POST OPTIMIZING ACCORDING TO THE DOCS\n",
    "    nn.utils.clip_grad_value_(rnn.parameters(), 4)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # ensure everything is sent back to cpu processing\n",
    "    rnn.to('cpu')\n",
    "    inp, target = inp.to('cpu'), target.to('cpu')\n",
    "    \n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), hidden\n",
    "\n",
    "# Note that these tests aren't completely extensive.\n",
    "# they are here to act as general checks on the expected outputs of your functions\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "\n",
    "With the structure of the network complete and data ready to be fed in the neural network, it's time to train it.\n",
    "\n",
    "### Train Loop\n",
    "\n",
    "The training loop is implemented for you in the `train_decoder` function. This function will train the network over all the batches for the number of epochs given. The model progress will be shown every number of batches. This number is set with the `show_every_n_batches` parameter. You'll set this parameter along with other parameters in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    \n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in tqdm(range(1, n_epochs + 1)):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
    "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Set and train the neural network with the following parameters:\n",
    "- Set `sequence_length` to the length of a sequence.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `num_epochs` to the number of epochs to train for.\n",
    "- Set `learning_rate` to the learning rate for an Adam optimizer.\n",
    "- Set `vocab_size` to the number of unique tokens in our vocabulary.\n",
    "- Set `output_size` to the desired size of the output.\n",
    "- Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.\n",
    "- Set `hidden_dim` to the hidden dimension of your RNN.\n",
    "- Set `n_layers` to the number of layers/cells in your RNN.\n",
    "- Set `show_every_n_batches` to the number of batches at which the neural network should print progress.\n",
    "\n",
    "If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "# Sequence Length\n",
    "sequence_length = 6 #13  # of words in a sequence\n",
    "# Batch Size\n",
    "batch_size = 32 # 32\n",
    "\n",
    "# data loader - do not change\n",
    "train_loader = batch_data(int_text, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Number of Epochs\n",
    "num_epochs = 30 #\n",
    "# Learning Rate\n",
    "learning_rate = 0.0005 # 0.001 0.002, 0.0015\n",
    "\n",
    "# Model parameters\n",
    "# Vocab size\n",
    "vocab_size = len(int_to_vocab)\n",
    "# Output size\n",
    "output_size = vocab_size\n",
    "# Embedding Dimension\n",
    "embedding_dim = 400 # 300\n",
    "# Hidden Dimension\n",
    "hidden_dim = 512\n",
    "# Number of RNN Layers\n",
    "n_layers = 2 \n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "In the next cell, you'll train the neural network on the pre-processed data.  If you have a hard time getting a good loss, you may consider changing your hyperparameters. In general, you may get better results with larger hidden and n_layer dimensions, but larger models take a longer time to train. \n",
    "> **You should aim for a loss less than 3.5.** \n",
    "\n",
    "You should also experiment with different sequence lengths, which determine the size of the long range dependencies that a model can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 30 epoch(s)...\n",
      "Epoch:    1/30    Loss: 5.631917074203491\n",
      "\n",
      "Epoch:    1/30    Loss: 5.097865256309509\n",
      "\n",
      "Epoch:    1/30    Loss: 4.950217853069305\n",
      "\n",
      "Epoch:    1/30    Loss: 4.823883620262146\n",
      "\n",
      "Epoch:    1/30    Loss: 4.684354959011078\n",
      "\n",
      "Epoch:    1/30    Loss: 4.631889041423798\n",
      "\n",
      "Epoch:    1/30    Loss: 4.6176121168136595\n",
      "\n",
      "Epoch:    1/30    Loss: 4.518433081150055\n",
      "\n",
      "Epoch:    1/30    Loss: 4.498312164783478\n",
      "\n",
      "Epoch:    1/30    Loss: 4.472153312683106\n",
      "\n",
      "Epoch:    1/30    Loss: 4.455683742523194\n",
      "\n",
      "Epoch:    1/30    Loss: 4.381301685333252\n",
      "\n",
      "Epoch:    1/30    Loss: 4.4505188164711\n",
      "\n",
      "Epoch:    1/30    Loss: 4.368369184017181\n",
      "\n",
      "Epoch:    1/30    Loss: 4.34871819114685\n",
      "\n",
      "Epoch:    1/30    Loss: 4.325979486942291\n",
      "\n",
      "Epoch:    1/30    Loss: 4.319601820468902\n",
      "\n",
      "Epoch:    1/30    Loss: 4.282609702110291\n",
      "\n",
      "Epoch:    1/30    Loss: 4.309314945697785\n",
      "\n",
      "Epoch:    1/30    Loss: 4.273182336807251\n",
      "\n",
      "Epoch:    1/30    Loss: 4.276075323581695\n",
      "\n",
      "Epoch:    1/30    Loss: 4.300496603488922\n",
      "\n",
      "Epoch:    1/30    Loss: 4.23530592918396\n",
      "\n",
      "Epoch:    1/30    Loss: 4.214100860118866\n",
      "\n",
      "Epoch:    1/30    Loss: 4.217958567142486\n",
      "\n",
      "Epoch:    1/30    Loss: 4.196063537597656\n",
      "\n",
      "Epoch:    1/30    Loss: 4.215746657848358\n",
      "\n",
      "Epoch:    1/30    Loss: 4.218126051902771\n",
      "\n",
      "Epoch:    1/30    Loss: 4.205175659179687\n",
      "\n",
      "Epoch:    1/30    Loss: 4.193860197067261\n",
      "\n",
      "Epoch:    1/30    Loss: 4.254257401943207\n",
      "\n",
      "Epoch:    1/30    Loss: 4.189019991397858\n",
      "\n",
      "Epoch:    1/30    Loss: 4.223018620014191\n",
      "\n",
      "Epoch:    1/30    Loss: 4.2070436115264895\n",
      "\n",
      "Epoch:    1/30    Loss: 4.126909224033356\n",
      "\n",
      "Epoch:    1/30    Loss: 4.155922897815705\n",
      "\n",
      "Epoch:    1/30    Loss: 4.135498289108276\n",
      "\n",
      "Epoch:    1/30    Loss: 4.21261622428894\n",
      "\n",
      "Epoch:    1/30    Loss: 4.176717845916748\n",
      "\n",
      "Epoch:    1/30    Loss: 4.080787917137146\n",
      "\n",
      "Epoch:    1/30    Loss: 4.077545582771301\n",
      "\n",
      "Epoch:    1/30    Loss: 4.128147468566895\n",
      "\n",
      "Epoch:    1/30    Loss: 4.127050583362579\n",
      "\n",
      "Epoch:    1/30    Loss: 4.129937519073486\n",
      "\n",
      "Epoch:    1/30    Loss: 4.147646582603454\n",
      "\n",
      "Epoch:    1/30    Loss: 4.165695779323578\n",
      "\n",
      "Epoch:    1/30    Loss: 4.164443606853485\n",
      "\n",
      "Epoch:    1/30    Loss: 4.100408516407013\n",
      "\n",
      "Epoch:    1/30    Loss: 4.115861623287201\n",
      "\n",
      "Epoch:    1/30    Loss: 4.115880532264709\n",
      "\n",
      "Epoch:    1/30    Loss: 4.10760435962677\n",
      "\n",
      "Epoch:    1/30    Loss: 4.084033433437347\n",
      "\n",
      "Epoch:    1/30    Loss: 4.09494924736023\n",
      "\n",
      "Epoch:    1/30    Loss: 4.103910660743713\n",
      "\n",
      "Epoch:    1/30    Loss: 4.121741914272309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                         | 1/30 [1:28:47<42:54:59, 5327.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/30    Loss: 4.008505147247488\n",
      "\n",
      "Epoch:    2/30    Loss: 3.918963326931\n",
      "\n",
      "Epoch:    2/30    Loss: 3.8957852029800417\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9429426741600038\n",
      "\n",
      "Epoch:    2/30    Loss: 3.938434164047241\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9215558671951296\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9544380650520323\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9503340520858763\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9450570974349977\n",
      "\n",
      "Epoch:    2/30    Loss: 3.938774064064026\n",
      "\n",
      "Epoch:    2/30    Loss: 3.956159104347229\n",
      "\n",
      "Epoch:    2/30    Loss: 3.926280095100403\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9352136788368224\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9956078724861146\n",
      "\n",
      "Epoch:    2/30    Loss: 3.924984833240509\n",
      "\n",
      "Epoch:    2/30    Loss: 3.968446300983429\n",
      "\n",
      "Epoch:    2/30    Loss: 4.028602971076966\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9883325910568237\n",
      "\n",
      "Epoch:    2/30    Loss: 3.990843740463257\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9720629196166994\n",
      "\n",
      "Epoch:    2/30    Loss: 4.01558452796936\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9775825123786928\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9807479090690614\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9804429941177366\n",
      "\n",
      "Epoch:    2/30    Loss: 4.004563749313355\n",
      "\n",
      "Epoch:    2/30    Loss: 3.96906640291214\n",
      "\n",
      "Epoch:    2/30    Loss: 4.018440111637116\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9738700399398805\n",
      "\n",
      "Epoch:    2/30    Loss: 3.982154948711395\n",
      "\n",
      "Epoch:    2/30    Loss: 4.007857037782669\n",
      "\n",
      "Epoch:    2/30    Loss: 4.041039813041687\n",
      "\n",
      "Epoch:    2/30    Loss: 3.974586472034454\n",
      "\n",
      "Epoch:    2/30    Loss: 4.036859162330628\n",
      "\n",
      "Epoch:    2/30    Loss: 4.02377548122406\n",
      "\n",
      "Epoch:    2/30    Loss: 4.024888132095337\n",
      "\n",
      "Epoch:    2/30    Loss: 4.042607425689697\n",
      "\n",
      "Epoch:    2/30    Loss: 4.003497412204743\n",
      "\n",
      "Epoch:    2/30    Loss: 4.014459278106689\n",
      "\n",
      "Epoch:    2/30    Loss: 3.997070761680603\n",
      "\n",
      "Epoch:    2/30    Loss: 4.030675038337708\n",
      "\n",
      "Epoch:    2/30    Loss: 4.0186627850532535\n",
      "\n",
      "Epoch:    2/30    Loss: 4.041777470588684\n",
      "\n",
      "Epoch:    2/30    Loss: 3.988102212429047\n",
      "\n",
      "Epoch:    2/30    Loss: 4.017594906806946\n",
      "\n",
      "Epoch:    2/30    Loss: 4.07922598028183\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9744401602745056\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9719607849121092\n",
      "\n",
      "Epoch:    2/30    Loss: 4.0366271257400514\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9705311851501466\n",
      "\n",
      "Epoch:    2/30    Loss: 4.005265634059906\n",
      "\n",
      "Epoch:    2/30    Loss: 4.081806377410889\n",
      "\n",
      "Epoch:    2/30    Loss: 4.002704897880554\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9761634583473207\n",
      "\n",
      "Epoch:    2/30    Loss: 3.9950856747627257\n",
      "\n",
      "Epoch:    2/30    Loss: 4.004902643680572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████                                                                       | 2/30 [2:57:09<41:19:04, 5312.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/30    Loss: 3.8994099548031365\n",
      "\n",
      "Epoch:    3/30    Loss: 3.799225700855255\n",
      "\n",
      "Epoch:    3/30    Loss: 3.846793550491333\n",
      "\n",
      "Epoch:    3/30    Loss: 3.809667894601822\n",
      "\n",
      "Epoch:    3/30    Loss: 3.841418756008148\n",
      "\n",
      "Epoch:    3/30    Loss: 3.821852278709412\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8655589270591735\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8054122309684755\n",
      "\n",
      "Epoch:    3/30    Loss: 3.879960611343384\n",
      "\n",
      "Epoch:    3/30    Loss: 3.7944295349121093\n",
      "\n",
      "Epoch:    3/30    Loss: 3.806439929008484\n",
      "\n",
      "Epoch:    3/30    Loss: 3.821813896656036\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8482629523277283\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8284632897377016\n",
      "\n",
      "Epoch:    3/30    Loss: 3.887773063659668\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8935196347236634\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8799717378616334\n",
      "\n",
      "Epoch:    3/30    Loss: 3.868943462371826\n",
      "\n",
      "Epoch:    3/30    Loss: 3.882346526145935\n",
      "\n",
      "Epoch:    3/30    Loss: 3.862254395008087\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8648422102928164\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8696413531303406\n",
      "\n",
      "Epoch:    3/30    Loss: 3.865200750589371\n",
      "\n",
      "Epoch:    3/30    Loss: 3.878178369522095\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9079254508018493\n",
      "\n",
      "Epoch:    3/30    Loss: 3.89723646068573\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8668375282287597\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9126767535209654\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8689757289886475\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9212221026420595\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8930052580833436\n",
      "\n",
      "Epoch:    3/30    Loss: 3.869201730966568\n",
      "\n",
      "Epoch:    3/30    Loss: 3.900793979167938\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9075495433807372\n",
      "\n",
      "Epoch:    3/30    Loss: 3.925341902256012\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9346156277656554\n",
      "\n",
      "Epoch:    3/30    Loss: 3.971795150279999\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8751284170150755\n",
      "\n",
      "Epoch:    3/30    Loss: 3.912518304347992\n",
      "\n",
      "Epoch:    3/30    Loss: 3.8777656974792483\n",
      "\n",
      "Epoch:    3/30    Loss: 3.905349310874939\n",
      "\n",
      "Epoch:    3/30    Loss: 3.90266716003418\n",
      "\n",
      "Epoch:    3/30    Loss: 3.975901895046234\n",
      "\n",
      "Epoch:    3/30    Loss: 3.900751783847809\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9273051290512084\n",
      "\n",
      "Epoch:    3/30    Loss: 3.94549974155426\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9228620834350587\n",
      "\n",
      "Epoch:    3/30    Loss: 3.894097255706787\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9129029908180235\n",
      "\n",
      "Epoch:    3/30    Loss: 3.942848384857178\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9570891790390013\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9814236316680907\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9653394560813906\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9289677090644837\n",
      "\n",
      "Epoch:    3/30    Loss: 3.9537345957756043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▌                                                                    | 3/30 [4:25:27<39:47:44, 5306.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    4/30    Loss: 3.832186190576923\n",
      "\n",
      "Epoch:    4/30    Loss: 3.6921060261726377\n",
      "\n",
      "Epoch:    4/30    Loss: 3.68658038854599\n",
      "\n",
      "Epoch:    4/30    Loss: 3.689423215389252\n",
      "\n",
      "Epoch:    4/30    Loss: 3.686260670185089\n",
      "\n",
      "Epoch:    4/30    Loss: 3.70146413230896\n",
      "\n",
      "Epoch:    4/30    Loss: 3.733857135057449\n",
      "\n",
      "Epoch:    4/30    Loss: 3.719928843021393\n",
      "\n",
      "Epoch:    4/30    Loss: 3.789642375946045\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7679910531044007\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7547266721725463\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7479183692932128\n",
      "\n",
      "Epoch:    4/30    Loss: 3.778973388195038\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7777021045684815\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8378233580589294\n",
      "\n",
      "Epoch:    4/30    Loss: 3.76205042552948\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8081252632141114\n",
      "\n",
      "Epoch:    4/30    Loss: 3.771701991558075\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7923474569320677\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7600563683509827\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8354115624427796\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7996078906059263\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7445200090408326\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8132543127536773\n",
      "\n",
      "Epoch:    4/30    Loss: 3.857749577045441\n",
      "\n",
      "Epoch:    4/30    Loss: 3.853165281295776\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8399261412620542\n",
      "\n",
      "Epoch:    4/30    Loss: 3.812202115535736\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8276392736434937\n",
      "\n",
      "Epoch:    4/30    Loss: 3.799859483718872\n",
      "\n",
      "Epoch:    4/30    Loss: 3.784520477771759\n",
      "\n",
      "Epoch:    4/30    Loss: 3.7904760413169862\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8590870871543883\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8247197117805483\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8565879535675047\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8125021727085113\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8291762127876283\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8162564010620117\n",
      "\n",
      "Epoch:    4/30    Loss: 3.870600679397583\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8246530623435975\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8741162362098693\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8770263438224792\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8370341515541075\n",
      "\n",
      "Epoch:    4/30    Loss: 3.9099445509910584\n",
      "\n",
      "Epoch:    4/30    Loss: 3.900855207443237\n",
      "\n",
      "Epoch:    4/30    Loss: 3.824777961730957\n",
      "\n",
      "Epoch:    4/30    Loss: 3.884204545021057\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8752291331291198\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8904425458908083\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8843505425453184\n",
      "\n",
      "Epoch:    4/30    Loss: 3.911829020500183\n",
      "\n",
      "Epoch:    4/30    Loss: 3.897341619491577\n",
      "\n",
      "Epoch:    4/30    Loss: 3.8571147742271426\n",
      "\n",
      "Epoch:    4/30    Loss: 3.9194299535751345\n",
      "\n",
      "Epoch:    4/30    Loss: 3.849450535774231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▏                                                                 | 4/30 [5:53:48<38:18:25, 5304.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    5/30    Loss: 3.726997880837912\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6228422985076905\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6325188179016115\n",
      "\n",
      "Epoch:    5/30    Loss: 3.652886266708374\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6655545897483828\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6106770949363707\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6836534395217897\n",
      "\n",
      "Epoch:    5/30    Loss: 3.667412700176239\n",
      "\n",
      "Epoch:    5/30    Loss: 3.690616961479187\n",
      "\n",
      "Epoch:    5/30    Loss: 3.645807926893234\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6547101020812987\n",
      "\n",
      "Epoch:    5/30    Loss: 3.657000521659851\n",
      "\n",
      "Epoch:    5/30    Loss: 3.6746967577934266\n",
      "\n",
      "Epoch:    5/30    Loss: 3.733260495662689\n",
      "\n",
      "Epoch:    5/30    Loss: 3.705128288269043\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7729429750442507\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7281570506095885\n",
      "\n",
      "Epoch:    5/30    Loss: 3.705665729045868\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7570131511688234\n",
      "\n",
      "Epoch:    5/30    Loss: 3.771129807949066\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7373681831359864\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7402976841926576\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7121589126586914\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7431380558013916\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7701449999809267\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7919176812171935\n",
      "\n",
      "Epoch:    5/30    Loss: 3.764324592113495\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7491736602783203\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7773178644180296\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7647066435813903\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7595362100601197\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8040855827331543\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7867597284317016\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7589841423034667\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7548013808727263\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7865351219177246\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8415294551849364\n",
      "\n",
      "Epoch:    5/30    Loss: 3.775359628200531\n",
      "\n",
      "Epoch:    5/30    Loss: 3.776378167629242\n",
      "\n",
      "Epoch:    5/30    Loss: 3.790743137359619\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7744625906944274\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8380808305740355\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8159708852767946\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8049427523612978\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7882083654403687\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8023357982635497\n",
      "\n",
      "Epoch:    5/30    Loss: 3.7814064483642578\n",
      "\n",
      "Epoch:    5/30    Loss: 3.84842636346817\n",
      "\n",
      "Epoch:    5/30    Loss: 3.78860711479187\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8467334332466128\n",
      "\n",
      "Epoch:    5/30    Loss: 3.837597181797028\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8561232099533083\n",
      "\n",
      "Epoch:    5/30    Loss: 3.807677894592285\n",
      "\n",
      "Epoch:    5/30    Loss: 3.8212684659957885\n",
      "\n",
      "Epoch:    5/30    Loss: 3.9000283658504484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▋                                                               | 5/30 [7:22:10<36:49:43, 5303.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    6/30    Loss: 3.68587368197213\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6296660013198854\n",
      "\n",
      "Epoch:    6/30    Loss: 3.59334138917923\n",
      "\n",
      "Epoch:    6/30    Loss: 3.5688861274719237\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6033987367153166\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6378572397232056\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6364768052101137\n",
      "\n",
      "Epoch:    6/30    Loss: 3.676026798725128\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6962621011734007\n",
      "\n",
      "Epoch:    6/30    Loss: 3.609839759349823\n",
      "\n",
      "Epoch:    6/30    Loss: 3.677213451385498\n",
      "\n",
      "Epoch:    6/30    Loss: 3.70227498626709\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6309004254341124\n",
      "\n",
      "Epoch:    6/30    Loss: 3.630266824245453\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6461907534599303\n",
      "\n",
      "Epoch:    6/30    Loss: 3.697872323989868\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6593619289398194\n",
      "\n",
      "Epoch:    6/30    Loss: 3.63392809009552\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6408277497291563\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6882145819664003\n",
      "\n",
      "Epoch:    6/30    Loss: 3.666427215099335\n",
      "\n",
      "Epoch:    6/30    Loss: 3.726888991355896\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7039469299316408\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7330370969772337\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6958478875160217\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6623880333900454\n",
      "\n",
      "Epoch:    6/30    Loss: 3.6862279357910155\n",
      "\n",
      "Epoch:    6/30    Loss: 3.762560242176056\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7159409918785093\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7515982489585875\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7864435362815856\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7242347395420072\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7434000248909\n",
      "\n",
      "Epoch:    6/30    Loss: 3.711419268131256\n",
      "\n",
      "Epoch:    6/30    Loss: 3.732938717365265\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7265324411392213\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7749985752105712\n",
      "\n",
      "Epoch:    6/30    Loss: 3.738078526496887\n",
      "\n",
      "Epoch:    6/30    Loss: 3.718008955955505\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7743883414268495\n",
      "\n",
      "Epoch:    6/30    Loss: 3.786806437969208\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7226971316337587\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7677915539741518\n",
      "\n",
      "Epoch:    6/30    Loss: 3.77289803981781\n",
      "\n",
      "Epoch:    6/30    Loss: 3.7350108988285067\n",
      "\n",
      "Epoch:    6/30    Loss: 3.790425528526306\n",
      "\n",
      "Epoch:    6/30    Loss: 3.790536218166351\n",
      "\n",
      "Epoch:    6/30    Loss: 3.75060298204422\n",
      "\n",
      "Epoch:    6/30    Loss: 3.800801989555359\n",
      "\n",
      "Epoch:    6/30    Loss: 3.774159327983856\n",
      "\n",
      "Epoch:    6/30    Loss: 3.813454437971115\n",
      "\n",
      "Epoch:    6/30    Loss: 3.790225993156433\n",
      "\n",
      "Epoch:    6/30    Loss: 3.8188661184310915\n",
      "\n",
      "Epoch:    6/30    Loss: 3.804193253993988\n",
      "\n",
      "Epoch:    6/30    Loss: 3.8053476791381837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▏                                                            | 6/30 [8:51:01<35:25:00, 5312.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    7/30    Loss: 3.6816013027703844\n",
      "\n",
      "Epoch:    7/30    Loss: 3.56193173122406\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5676235575675963\n",
      "\n",
      "Epoch:    7/30    Loss: 3.585062430858612\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5824443867206575\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5545086798667906\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6113217196464538\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5921768593788146\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5556575562953947\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5599921560287475\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6122620639801024\n",
      "\n",
      "Epoch:    7/30    Loss: 3.627613195896149\n",
      "\n",
      "Epoch:    7/30    Loss: 3.604840114116669\n",
      "\n",
      "Epoch:    7/30    Loss: 3.5960262050628664\n",
      "\n",
      "Epoch:    7/30    Loss: 3.61263539981842\n",
      "\n",
      "Epoch:    7/30    Loss: 3.660872908592224\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6758413367271423\n",
      "\n",
      "Epoch:    7/30    Loss: 3.668942475557327\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6991114625930788\n",
      "\n",
      "Epoch:    7/30    Loss: 3.61775794839859\n",
      "\n",
      "Epoch:    7/30    Loss: 3.674760806560516\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6467264499664305\n",
      "\n",
      "Epoch:    7/30    Loss: 3.655091178894043\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6444779019355775\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6457598342895507\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6907823076248167\n",
      "\n",
      "Epoch:    7/30    Loss: 3.672202241420746\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7131035437583924\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7040826725959777\n",
      "\n",
      "Epoch:    7/30    Loss: 3.654906186103821\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6984796233177186\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7110261125564574\n",
      "\n",
      "Epoch:    7/30    Loss: 3.677360348701477\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7531063838005068\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6869010787010192\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6942605781555176\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7313017311096193\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7201574192047118\n",
      "\n",
      "Epoch:    7/30    Loss: 3.6954270048141478\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7730271639823916\n",
      "\n",
      "Epoch:    7/30    Loss: 3.70448495554924\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7901064119338987\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7323510546684266\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7232456870079043\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7078507804870604\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7823810472488404\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7788173537254335\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7519491176605224\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7809981088638307\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7830120387077333\n",
      "\n",
      "Epoch:    7/30    Loss: 3.761579559803009\n",
      "\n",
      "Epoch:    7/30    Loss: 3.752715636730194\n",
      "\n",
      "Epoch:    7/30    Loss: 3.7827321033477785\n",
      "\n",
      "Epoch:    7/30    Loss: 3.730851263523102\n",
      "\n",
      "Epoch:    7/30    Loss: 3.8067320251464842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████▌                                                         | 7/30 [10:23:55<34:29:19, 5398.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    8/30    Loss: 3.6230599577443203\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5515389428138735\n",
      "\n",
      "Epoch:    8/30    Loss: 3.555655373096466\n",
      "\n",
      "Epoch:    8/30    Loss: 3.587378053188324\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5994310932159426\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5696857936382296\n",
      "\n",
      "Epoch:    8/30    Loss: 3.54079772567749\n",
      "\n",
      "Epoch:    8/30    Loss: 3.603544500350952\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5816437225341797\n",
      "\n",
      "Epoch:    8/30    Loss: 3.563434537410736\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5925916323661804\n",
      "\n",
      "Epoch:    8/30    Loss: 3.5451888389587403\n",
      "\n",
      "Epoch:    8/30    Loss: 3.617147211551666\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6178519525527952\n",
      "\n",
      "Epoch:    8/30    Loss: 3.563261653661728\n",
      "\n",
      "Epoch:    8/30    Loss: 3.599525492668152\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6344737606048585\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6290430846214297\n",
      "\n",
      "Epoch:    8/30    Loss: 3.64609357213974\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6213801383972166\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6168046741485598\n",
      "\n",
      "Epoch:    8/30    Loss: 3.631551574230194\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6494792985916136\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6110103783607483\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6308856029510497\n",
      "\n",
      "Epoch:    8/30    Loss: 3.670447873592377\n",
      "\n",
      "Epoch:    8/30    Loss: 3.651433882713318\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6693971490859987\n",
      "\n",
      "Epoch:    8/30    Loss: 3.619174883842468\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7454659194946287\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6185435876846315\n",
      "\n",
      "Epoch:    8/30    Loss: 3.706959412574768\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6629024147987366\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6828018913269043\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6991369638442992\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7258316841125487\n",
      "\n",
      "Epoch:    8/30    Loss: 3.720973588466644\n",
      "\n",
      "Epoch:    8/30    Loss: 3.746399372577667\n",
      "\n",
      "Epoch:    8/30    Loss: 3.70616210436821\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7066266932487486\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7521697363853455\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7298024215698242\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7125452268123627\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6795071988105774\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6822697224617005\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6943318247795105\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7732730760574342\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7169851264953615\n",
      "\n",
      "Epoch:    8/30    Loss: 3.727991011619568\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7265301356315614\n",
      "\n",
      "Epoch:    8/30    Loss: 3.736635789632797\n",
      "\n",
      "Epoch:    8/30    Loss: 3.770542164325714\n",
      "\n",
      "Epoch:    8/30    Loss: 3.6981336812973025\n",
      "\n",
      "Epoch:    8/30    Loss: 3.7072710123062134\n",
      "\n",
      "Epoch:    8/30    Loss: 3.769292127132416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████                                                       | 8/30 [11:52:33<32:49:55, 5372.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    9/30    Loss: 3.61660611330784\n",
      "\n",
      "Epoch:    9/30    Loss: 3.524590829372406\n",
      "\n",
      "Epoch:    9/30    Loss: 3.532393539428711\n",
      "\n",
      "Epoch:    9/30    Loss: 3.516826924562454\n",
      "\n",
      "Epoch:    9/30    Loss: 3.4874437756538392\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5336554980278017\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5567444751262665\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5707269701957705\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6041978414058686\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5341901228427886\n",
      "\n",
      "Epoch:    9/30    Loss: 3.553494776248932\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5309085812568664\n",
      "\n",
      "Epoch:    9/30    Loss: 3.609269581794739\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5853527956008913\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5547876825332643\n",
      "\n",
      "Epoch:    9/30    Loss: 3.562278295516968\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6064281997680663\n",
      "\n",
      "Epoch:    9/30    Loss: 3.574358414173126\n",
      "\n",
      "Epoch:    9/30    Loss: 3.574115306854248\n",
      "\n",
      "Epoch:    9/30    Loss: 3.5898968517780303\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6003330073356627\n",
      "\n",
      "Epoch:    9/30    Loss: 3.660429952144623\n",
      "\n",
      "Epoch:    9/30    Loss: 3.648561640739441\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6612147064208984\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6025944695472716\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6122878351211547\n",
      "\n",
      "Epoch:    9/30    Loss: 3.684747298717499\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6857687208652496\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6792563681602477\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6127390398979187\n",
      "\n",
      "Epoch:    9/30    Loss: 3.649663029432297\n",
      "\n",
      "Epoch:    9/30    Loss: 3.656858414173126\n",
      "\n",
      "Epoch:    9/30    Loss: 3.672992507457733\n",
      "\n",
      "Epoch:    9/30    Loss: 3.625988342285156\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6526866736412047\n",
      "\n",
      "Epoch:    9/30    Loss: 3.654288643360138\n",
      "\n",
      "Epoch:    9/30    Loss: 3.653970107555389\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6534525542259217\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6570533094406126\n",
      "\n",
      "Epoch:    9/30    Loss: 3.635778856277466\n",
      "\n",
      "Epoch:    9/30    Loss: 3.713727328300476\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6983903303146364\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7034960098266603\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6888753175735474\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7111124706268313\n",
      "\n",
      "Epoch:    9/30    Loss: 3.742447021007538\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7087231721878053\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7110744581222534\n",
      "\n",
      "Epoch:    9/30    Loss: 3.683876324892044\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7179415941238405\n",
      "\n",
      "Epoch:    9/30    Loss: 3.719718195438385\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7345187044143677\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7060420236587523\n",
      "\n",
      "Epoch:    9/30    Loss: 3.6896666412353514\n",
      "\n",
      "Epoch:    9/30    Loss: 3.7732519125938415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▌                                                    | 9/30 [13:21:32<31:16:44, 5362.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10/30    Loss: 3.578802311067429\n",
      "\n",
      "Epoch:   10/30    Loss: 3.4798627588748934\n",
      "\n",
      "Epoch:   10/30    Loss: 3.487854258775711\n",
      "\n",
      "Epoch:   10/30    Loss: 3.471113750457764\n",
      "\n",
      "Epoch:   10/30    Loss: 3.505301947593689\n",
      "\n",
      "Epoch:   10/30    Loss: 3.495627576828003\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5509139246940613\n",
      "\n",
      "Epoch:   10/30    Loss: 3.501130721092224\n",
      "\n",
      "Epoch:   10/30    Loss: 3.507650625705719\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5277707014083863\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6099181289672853\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5869316868782044\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5653655672073366\n",
      "\n",
      "Epoch:   10/30    Loss: 3.556050061225891\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5832553400993348\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5383712038993838\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5741748943328857\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5985405430793764\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5681695113182066\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5900329041481016\n",
      "\n",
      "Epoch:   10/30    Loss: 3.586625056743622\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5979245653152465\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5787547550201415\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6254462475776674\n",
      "\n",
      "Epoch:   10/30    Loss: 3.5828713750839234\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6066553568840027\n",
      "\n",
      "Epoch:   10/30    Loss: 3.568424258232117\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6139315440654753\n",
      "\n",
      "Epoch:   10/30    Loss: 3.63497136592865\n",
      "\n",
      "Epoch:   10/30    Loss: 3.605989727973938\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6227513818740844\n",
      "\n",
      "Epoch:   10/30    Loss: 3.611933698177338\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6787213549613953\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6087818975448607\n",
      "\n",
      "Epoch:   10/30    Loss: 3.638311369419098\n",
      "\n",
      "Epoch:   10/30    Loss: 3.622068464756012\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6353807201385497\n",
      "\n",
      "Epoch:   10/30    Loss: 3.624291036128998\n",
      "\n",
      "Epoch:   10/30    Loss: 3.682097801208496\n",
      "\n",
      "Epoch:   10/30    Loss: 3.690959365129471\n",
      "\n",
      "Epoch:   10/30    Loss: 3.627429166316986\n",
      "\n",
      "Epoch:   10/30    Loss: 3.7157454302310944\n",
      "\n",
      "Epoch:   10/30    Loss: 3.678684859752655\n",
      "\n",
      "Epoch:   10/30    Loss: 3.706188286304474\n",
      "\n",
      "Epoch:   10/30    Loss: 3.657085110664368\n",
      "\n",
      "Epoch:   10/30    Loss: 3.693160204410553\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6786865725517273\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6980533385276795\n",
      "\n",
      "Epoch:   10/30    Loss: 3.7249205584526064\n",
      "\n",
      "Epoch:   10/30    Loss: 3.668332589149475\n",
      "\n",
      "Epoch:   10/30    Loss: 3.6504351127147676\n",
      "\n",
      "Epoch:   10/30    Loss: 3.7055771679878236\n",
      "\n",
      "Epoch:   10/30    Loss: 3.7371535439491272\n",
      "\n",
      "Epoch:   10/30    Loss: 3.67718266248703\n",
      "\n",
      "Epoch:   10/30    Loss: 3.7115579662323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████▋                                                 | 10/30 [14:50:10<29:42:46, 5348.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   11/30    Loss: 3.6033901731082683\n",
      "\n",
      "Epoch:   11/30    Loss: 3.4352957661151886\n",
      "\n",
      "Epoch:   11/30    Loss: 3.4904497265815735\n",
      "\n",
      "Epoch:   11/30    Loss: 3.4759103438854217\n",
      "\n",
      "Epoch:   11/30    Loss: 3.4702237484455107\n",
      "\n",
      "Epoch:   11/30    Loss: 3.508020347595215\n",
      "\n",
      "Epoch:   11/30    Loss: 3.509343846797943\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5044080600738527\n",
      "\n",
      "Epoch:   11/30    Loss: 3.4578642861843107\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5270817995071413\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5284377040863038\n",
      "\n",
      "Epoch:   11/30    Loss: 3.510408414363861\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5536844573020936\n",
      "\n",
      "Epoch:   11/30    Loss: 3.565339418172836\n",
      "\n",
      "Epoch:   11/30    Loss: 3.552330526828766\n",
      "\n",
      "Epoch:   11/30    Loss: 3.57286190366745\n",
      "\n",
      "Epoch:   11/30    Loss: 3.532018196105957\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5041924102306368\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5945765562057495\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5122441053390503\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6075557169914245\n",
      "\n",
      "Epoch:   11/30    Loss: 3.572074087381363\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5220962533950804\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6484251790046693\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5508855519294737\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6209365854263305\n",
      "\n",
      "Epoch:   11/30    Loss: 3.598315480232239\n",
      "\n",
      "Epoch:   11/30    Loss: 3.642369438648224\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6115753178596495\n",
      "\n",
      "Epoch:   11/30    Loss: 3.5805232224464416\n",
      "\n",
      "Epoch:   11/30    Loss: 3.569543429851532\n",
      "\n",
      "Epoch:   11/30    Loss: 3.620275499343872\n",
      "\n",
      "Epoch:   11/30    Loss: 3.642006850719452\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6430824871063234\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6831378479003907\n",
      "\n",
      "Epoch:   11/30    Loss: 3.626987874031067\n",
      "\n",
      "Epoch:   11/30    Loss: 3.67781817650795\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6867952442169187\n",
      "\n",
      "Epoch:   11/30    Loss: 3.63812455034256\n",
      "\n",
      "Epoch:   11/30    Loss: 3.674839862585068\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6891166362762453\n",
      "\n",
      "Epoch:   11/30    Loss: 3.637743010520935\n",
      "\n",
      "Epoch:   11/30    Loss: 3.669784294128418\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6730150604248046\n",
      "\n",
      "Epoch:   11/30    Loss: 3.632492003440857\n",
      "\n",
      "Epoch:   11/30    Loss: 3.63819265794754\n",
      "\n",
      "Epoch:   11/30    Loss: 3.668492378234863\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6902334752082826\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6754304511547087\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6440073370933534\n",
      "\n",
      "Epoch:   11/30    Loss: 3.636555800199509\n",
      "\n",
      "Epoch:   11/30    Loss: 3.671865560054779\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6461317501068113\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6352456278800966\n",
      "\n",
      "Epoch:   11/30    Loss: 3.6814318108558655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████████████████▏                                              | 11/30 [16:18:45<28:10:28, 5338.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   12/30    Loss: 3.553804519779318\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4541841282844543\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4209522023200987\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4718785381317137\n",
      "\n",
      "Epoch:   12/30    Loss: 3.466881885766983\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4742903203964235\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5596491849422454\n",
      "\n",
      "Epoch:   12/30    Loss: 3.513122386932373\n",
      "\n",
      "Epoch:   12/30    Loss: 3.50522647857666\n",
      "\n",
      "Epoch:   12/30    Loss: 3.50719207239151\n",
      "\n",
      "Epoch:   12/30    Loss: 3.514469165802002\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5429114027023316\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5505402460098265\n",
      "\n",
      "Epoch:   12/30    Loss: 3.518008386850357\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5414665184020997\n",
      "\n",
      "Epoch:   12/30    Loss: 3.529334427833557\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4895804426670076\n",
      "\n",
      "Epoch:   12/30    Loss: 3.526210478782654\n",
      "\n",
      "Epoch:   12/30    Loss: 3.54384601688385\n",
      "\n",
      "Epoch:   12/30    Loss: 3.52476283788681\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5605467710494993\n",
      "\n",
      "Epoch:   12/30    Loss: 3.563469889640808\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5627431983947755\n",
      "\n",
      "Epoch:   12/30    Loss: 3.559777325153351\n",
      "\n",
      "Epoch:   12/30    Loss: 3.4994036498069763\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5461788363456725\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6107432355880738\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5880828666687012\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5932867426872255\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6132911076545717\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6140402207374573\n",
      "\n",
      "Epoch:   12/30    Loss: 3.564004882335663\n",
      "\n",
      "Epoch:   12/30    Loss: 3.591784995555878\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6018876733779908\n",
      "\n",
      "Epoch:   12/30    Loss: 3.633669078350067\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5822267541885378\n",
      "\n",
      "Epoch:   12/30    Loss: 3.67114342546463\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6015507369041444\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6535057628154757\n",
      "\n",
      "Epoch:   12/30    Loss: 3.5845785851478578\n",
      "\n",
      "Epoch:   12/30    Loss: 3.620942943096161\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6165572028160096\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6568958964347837\n",
      "\n",
      "Epoch:   12/30    Loss: 3.615183992385864\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6070197196006775\n",
      "\n",
      "Epoch:   12/30    Loss: 3.656589833498001\n",
      "\n",
      "Epoch:   12/30    Loss: 3.63488117313385\n",
      "\n",
      "Epoch:   12/30    Loss: 3.681676587104797\n",
      "\n",
      "Epoch:   12/30    Loss: 3.69299995803833\n",
      "\n",
      "Epoch:   12/30    Loss: 3.589795409202576\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6308054370880125\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6497097125053406\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6885985078811645\n",
      "\n",
      "Epoch:   12/30    Loss: 3.6552777442932127\n",
      "\n",
      "Epoch:   12/30    Loss: 3.631462396144867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████▌                                            | 12/30 [17:47:34<26:40:38, 5335.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   13/30    Loss: 3.5125275907320965\n",
      "\n",
      "Epoch:   13/30    Loss: 3.429282423019409\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4122619426250456\n",
      "\n",
      "Epoch:   13/30    Loss: 3.469215061187744\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4689070501327515\n",
      "\n",
      "Epoch:   13/30    Loss: 3.45351057100296\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4679849219322203\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4485197494029998\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4247869374752047\n",
      "\n",
      "Epoch:   13/30    Loss: 3.484955187797546\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5158551993370057\n",
      "\n",
      "Epoch:   13/30    Loss: 3.49525355887413\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4925254926681517\n",
      "\n",
      "Epoch:   13/30    Loss: 3.510553503036499\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5038394284248353\n",
      "\n",
      "Epoch:   13/30    Loss: 3.4894743285179137\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5141936392784117\n",
      "\n",
      "Epoch:   13/30    Loss: 3.522715606212616\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5524075503349306\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5473921661376955\n",
      "\n",
      "Epoch:   13/30    Loss: 3.527823914051056\n",
      "\n",
      "Epoch:   13/30    Loss: 3.495530501127243\n",
      "\n",
      "Epoch:   13/30    Loss: 3.478305121421814\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5224019451141357\n",
      "\n",
      "Epoch:   13/30    Loss: 3.57689195394516\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5822629759311675\n",
      "\n",
      "Epoch:   13/30    Loss: 3.538079144001007\n",
      "\n",
      "Epoch:   13/30    Loss: 3.574456126213074\n",
      "\n",
      "Epoch:   13/30    Loss: 3.561151517868042\n",
      "\n",
      "Epoch:   13/30    Loss: 3.546132107257843\n",
      "\n",
      "Epoch:   13/30    Loss: 3.555850102186203\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5311625270843505\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5823553392887115\n",
      "\n",
      "Epoch:   13/30    Loss: 3.565072214603424\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5681893935203552\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5785245044231413\n",
      "\n",
      "Epoch:   13/30    Loss: 3.617789514541626\n",
      "\n",
      "Epoch:   13/30    Loss: 3.582282187461853\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5925066232681275\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6202772197723387\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6345214734077453\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5738136620521543\n",
      "\n",
      "Epoch:   13/30    Loss: 3.633729872941971\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6728371767997743\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6384259433746338\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6017050714492798\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6037925832271576\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6247853050231935\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6144959025382994\n",
      "\n",
      "Epoch:   13/30    Loss: 3.601374106884003\n",
      "\n",
      "Epoch:   13/30    Loss: 3.5878571887016295\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6638776512145994\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6161879329681397\n",
      "\n",
      "Epoch:   13/30    Loss: 3.644837588787079\n",
      "\n",
      "Epoch:   13/30    Loss: 3.6375470714569094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████                                          | 13/30 [19:16:10<25:10:03, 5329.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   14/30    Loss: 3.5303120887360975\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4304545814990997\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4453576736450193\n",
      "\n",
      "Epoch:   14/30    Loss: 3.42143319940567\n",
      "\n",
      "Epoch:   14/30    Loss: 3.438178635120392\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4582401599884034\n",
      "\n",
      "Epoch:   14/30    Loss: 3.437364414215088\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4660251145362855\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4502356443405153\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4571262645721434\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4414577460289\n",
      "\n",
      "Epoch:   14/30    Loss: 3.423362102270126\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4707173237800597\n",
      "\n",
      "Epoch:   14/30    Loss: 3.477180181980133\n",
      "\n",
      "Epoch:   14/30    Loss: 3.528030019760132\n",
      "\n",
      "Epoch:   14/30    Loss: 3.478130723953247\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4874753737449646\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5303336572647095\n",
      "\n",
      "Epoch:   14/30    Loss: 3.503850276708603\n",
      "\n",
      "Epoch:   14/30    Loss: 3.46273251748085\n",
      "\n",
      "Epoch:   14/30    Loss: 3.475116053581238\n",
      "\n",
      "Epoch:   14/30    Loss: 3.4897886228561403\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5117222366333007\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5020581903457644\n",
      "\n",
      "Epoch:   14/30    Loss: 3.523901609182358\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5569777426719664\n",
      "\n",
      "Epoch:   14/30    Loss: 3.548424847126007\n",
      "\n",
      "Epoch:   14/30    Loss: 3.484707728385925\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5555124492645263\n",
      "\n",
      "Epoch:   14/30    Loss: 3.581097716331482\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5820263481140135\n",
      "\n",
      "Epoch:   14/30    Loss: 3.594464960575104\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5348253698348997\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5541404149532316\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5406917996406557\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5618939027786256\n",
      "\n",
      "Epoch:   14/30    Loss: 3.54221804022789\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5941564631462097\n",
      "\n",
      "Epoch:   14/30    Loss: 3.594809989452362\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5797613492012026\n",
      "\n",
      "Epoch:   14/30    Loss: 3.645384265422821\n",
      "\n",
      "Epoch:   14/30    Loss: 3.606108377456665\n",
      "\n",
      "Epoch:   14/30    Loss: 3.633577126979828\n",
      "\n",
      "Epoch:   14/30    Loss: 3.603513040304184\n",
      "\n",
      "Epoch:   14/30    Loss: 3.6349571413993838\n",
      "\n",
      "Epoch:   14/30    Loss: 3.6187312960624696\n",
      "\n",
      "Epoch:   14/30    Loss: 3.6144834570884705\n",
      "\n",
      "Epoch:   14/30    Loss: 3.6004276218414306\n",
      "\n",
      "Epoch:   14/30    Loss: 3.633045651435852\n",
      "\n",
      "Epoch:   14/30    Loss: 3.58561224937439\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5815461025238036\n",
      "\n",
      "Epoch:   14/30    Loss: 3.585413432121277\n",
      "\n",
      "Epoch:   14/30    Loss: 3.612221778392792\n",
      "\n",
      "Epoch:   14/30    Loss: 3.638663094997406\n",
      "\n",
      "Epoch:   14/30    Loss: 3.5984439764022826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████▌                                       | 14/30 [20:44:50<23:40:24, 5326.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   15/30    Loss: 3.50297654068823\n",
      "\n",
      "Epoch:   15/30    Loss: 3.3729736185073853\n",
      "\n",
      "Epoch:   15/30    Loss: 3.411397748231888\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4210673718452456\n",
      "\n",
      "Epoch:   15/30    Loss: 3.42358996963501\n",
      "\n",
      "Epoch:   15/30    Loss: 3.38073948264122\n",
      "\n",
      "Epoch:   15/30    Loss: 3.434092507839203\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4446430487632753\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4573812203407286\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4367351350784303\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4691746559143066\n",
      "\n",
      "Epoch:   15/30    Loss: 3.437225857257843\n",
      "\n",
      "Epoch:   15/30    Loss: 3.446003210783005\n",
      "\n",
      "Epoch:   15/30    Loss: 3.45793133854866\n",
      "\n",
      "Epoch:   15/30    Loss: 3.484265110015869\n",
      "\n",
      "Epoch:   15/30    Loss: 3.439509865760803\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4743362028598783\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5110875272750857\n",
      "\n",
      "Epoch:   15/30    Loss: 3.481400855064392\n",
      "\n",
      "Epoch:   15/30    Loss: 3.457356069326401\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4838258237838744\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5304740118980407\n",
      "\n",
      "Epoch:   15/30    Loss: 3.467144582271576\n",
      "\n",
      "Epoch:   15/30    Loss: 3.539731790304184\n",
      "\n",
      "Epoch:   15/30    Loss: 3.52090863609314\n",
      "\n",
      "Epoch:   15/30    Loss: 3.4664039039611816\n",
      "\n",
      "Epoch:   15/30    Loss: 3.513111502170563\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5367447690963747\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5748467888832094\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5732451491355897\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5430683722496035\n",
      "\n",
      "Epoch:   15/30    Loss: 3.503691330909729\n",
      "\n",
      "Epoch:   15/30    Loss: 3.55760866856575\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5571913132667543\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6011815195083616\n",
      "\n",
      "Epoch:   15/30    Loss: 3.584195499420166\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5556485023498534\n",
      "\n",
      "Epoch:   15/30    Loss: 3.508727703809738\n",
      "\n",
      "Epoch:   15/30    Loss: 3.550931212425232\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5850768172740937\n",
      "\n",
      "Epoch:   15/30    Loss: 3.604196079969406\n",
      "\n",
      "Epoch:   15/30    Loss: 3.544719144821167\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5902050375938415\n",
      "\n",
      "Epoch:   15/30    Loss: 3.590723515033722\n",
      "\n",
      "Epoch:   15/30    Loss: 3.591961880683899\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6095583810806273\n",
      "\n",
      "Epoch:   15/30    Loss: 3.606776134490967\n",
      "\n",
      "Epoch:   15/30    Loss: 3.5991459894180298\n",
      "\n",
      "Epoch:   15/30    Loss: 3.638881374835968\n",
      "\n",
      "Epoch:   15/30    Loss: 3.609961104154587\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6471907494068145\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6272895319461824\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6453223297595976\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6604152297973633\n",
      "\n",
      "Epoch:   15/30    Loss: 3.6450949878692627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████                                     | 15/30 [22:13:39<22:11:48, 5327.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   16/30    Loss: 3.4652401233316827\n",
      "\n",
      "Epoch:   16/30    Loss: 3.369226227045059\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4032500133514403\n",
      "\n",
      "Epoch:   16/30    Loss: 3.421091283798218\n",
      "\n",
      "Epoch:   16/30    Loss: 3.401316578626633\n",
      "\n",
      "Epoch:   16/30    Loss: 3.3912287034988404\n",
      "\n",
      "Epoch:   16/30    Loss: 3.3830756177902224\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4126068913936614\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4675163168907166\n",
      "\n",
      "Epoch:   16/30    Loss: 3.449108938217163\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4741263136863707\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4416258907318116\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5040807909965515\n",
      "\n",
      "Epoch:   16/30    Loss: 3.456043746948242\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4521980276107787\n",
      "\n",
      "Epoch:   16/30    Loss: 3.456602116584778\n",
      "\n",
      "Epoch:   16/30    Loss: 3.522655872821808\n",
      "\n",
      "Epoch:   16/30    Loss: 3.456723768234253\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4688457326889037\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4962055640220644\n",
      "\n",
      "Epoch:   16/30    Loss: 3.491801467895508\n",
      "\n",
      "Epoch:   16/30    Loss: 3.464520656585693\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4923647775650024\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5582475366592408\n",
      "\n",
      "Epoch:   16/30    Loss: 3.471301682472229\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5258405854701995\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4957831506729127\n",
      "\n",
      "Epoch:   16/30    Loss: 3.513081639289856\n",
      "\n",
      "Epoch:   16/30    Loss: 3.4872196135520936\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5642673177719115\n",
      "\n",
      "Epoch:   16/30    Loss: 3.54767266535759\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5396714582443236\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5393360657691955\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5508189721107484\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5659756577014923\n",
      "\n",
      "Epoch:   16/30    Loss: 3.517813276767731\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5778755779266356\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5315535793304442\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5696581292152403\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5628607501983645\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5748965096473695\n",
      "\n",
      "Epoch:   16/30    Loss: 3.602624571323395\n",
      "\n",
      "Epoch:   16/30    Loss: 3.550467804431915\n",
      "\n",
      "Epoch:   16/30    Loss: 3.549276160001755\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5884768476486206\n",
      "\n",
      "Epoch:   16/30    Loss: 3.534187686920166\n",
      "\n",
      "Epoch:   16/30    Loss: 3.6192093086242676\n",
      "\n",
      "Epoch:   16/30    Loss: 3.5920505809783934\n",
      "\n",
      "Epoch:   16/30    Loss: 3.597664402484894\n",
      "\n",
      "Epoch:   16/30    Loss: 3.556173301696777\n",
      "\n",
      "Epoch:   16/30    Loss: 3.642882911205292\n",
      "\n",
      "Epoch:   16/30    Loss: 3.616045252799988\n",
      "\n",
      "Epoch:   16/30    Loss: 3.6000502204895017\n",
      "\n",
      "Epoch:   16/30    Loss: 3.550644563674927\n",
      "\n",
      "Epoch:   16/30    Loss: 3.6125732576847076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████▍                                  | 16/30 [23:43:01<20:45:31, 5337.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   17/30    Loss: 3.50208817690543\n",
      "\n",
      "Epoch:   17/30    Loss: 3.381022962331772\n",
      "\n",
      "Epoch:   17/30    Loss: 3.391701043367386\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4045763273239134\n",
      "\n",
      "Epoch:   17/30    Loss: 3.3829783506393434\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4211393570899964\n",
      "\n",
      "Epoch:   17/30    Loss: 3.3600716335773466\n",
      "\n",
      "Epoch:   17/30    Loss: 3.388611101150513\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4326385803222657\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4101460833549497\n",
      "\n",
      "Epoch:   17/30    Loss: 3.419406716585159\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4693716201782228\n",
      "\n",
      "Epoch:   17/30    Loss: 3.483631230831146\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4555358505249023\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4196871726512907\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4428594019412992\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4348740799427033\n",
      "\n",
      "Epoch:   17/30    Loss: 3.451211416721344\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4596032817363738\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4659240071773527\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4960720632076265\n",
      "\n",
      "Epoch:   17/30    Loss: 3.4915813302993772\n",
      "\n",
      "Epoch:   17/30    Loss: 3.519321602344513\n",
      "\n",
      "Epoch:   17/30    Loss: 3.478849718570709\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5149221472740173\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5218620970249175\n",
      "\n",
      "Epoch:   17/30    Loss: 3.527681994438171\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5268420910835268\n",
      "\n",
      "Epoch:   17/30    Loss: 3.494362232208252\n",
      "\n",
      "Epoch:   17/30    Loss: 3.498956375360489\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5266235022544863\n",
      "\n",
      "Epoch:   17/30    Loss: 3.532058503627777\n",
      "\n",
      "Epoch:   17/30    Loss: 3.510568545818329\n",
      "\n",
      "Epoch:   17/30    Loss: 3.509793961048126\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5468305122852324\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5638200268745424\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5168804507255556\n",
      "\n",
      "Epoch:   17/30    Loss: 3.529601150035858\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5646416578292848\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5649327878952026\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5552399015426634\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5596214096546173\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5720601103305816\n",
      "\n",
      "Epoch:   17/30    Loss: 3.56019753408432\n",
      "\n",
      "Epoch:   17/30    Loss: 3.59364834856987\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5776635246276856\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5810883350372316\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5916356990337373\n",
      "\n",
      "Epoch:   17/30    Loss: 3.6203519122600554\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5501305212974548\n",
      "\n",
      "Epoch:   17/30    Loss: 3.5956826114654543\n",
      "\n",
      "Epoch:   17/30    Loss: 3.531394118309021\n",
      "\n",
      "Epoch:   17/30    Loss: 3.6020401833057405\n",
      "\n",
      "Epoch:   17/30    Loss: 3.6148547110557554\n",
      "\n",
      "Epoch:   17/30    Loss: 3.667963432312012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████▉                                | 17/30 [25:12:39<19:19:06, 5349.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   18/30    Loss: 3.4568133705840838\n",
      "\n",
      "Epoch:   18/30    Loss: 3.3688667340278626\n",
      "\n",
      "Epoch:   18/30    Loss: 3.3893751225471496\n",
      "\n",
      "Epoch:   18/30    Loss: 3.40066170501709\n",
      "\n",
      "Epoch:   18/30    Loss: 3.3906794481277465\n",
      "\n",
      "Epoch:   18/30    Loss: 3.3894803099632265\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4166931672096252\n",
      "\n",
      "Epoch:   18/30    Loss: 3.3979230551719666\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4214095392227173\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4127734155654905\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4196831965446473\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4171471118927004\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4218311128616334\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4675572514533997\n",
      "\n",
      "Epoch:   18/30    Loss: 3.449531935453415\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4550678164958954\n",
      "\n",
      "Epoch:   18/30    Loss: 3.473691155433655\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4725668671131134\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4899389209747316\n",
      "\n",
      "Epoch:   18/30    Loss: 3.490125506877899\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4525819437503813\n",
      "\n",
      "Epoch:   18/30    Loss: 3.458986424922943\n",
      "\n",
      "Epoch:   18/30    Loss: 3.463951851129532\n",
      "\n",
      "Epoch:   18/30    Loss: 3.501833002090454\n",
      "\n",
      "Epoch:   18/30    Loss: 3.504058746814728\n",
      "\n",
      "Epoch:   18/30    Loss: 3.497093194723129\n",
      "\n",
      "Epoch:   18/30    Loss: 3.4835068261623383\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5173363790512084\n",
      "\n",
      "Epoch:   18/30    Loss: 3.535136959552765\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5434835729598997\n",
      "\n",
      "Epoch:   18/30    Loss: 3.505915671825409\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5280336248874664\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5331662366390226\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5322156331539154\n",
      "\n",
      "Epoch:   18/30    Loss: 3.523095974683762\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5237743701934816\n",
      "\n",
      "Epoch:   18/30    Loss: 3.530466238975525\n",
      "\n",
      "Epoch:   18/30    Loss: 3.549792778491974\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5534562706947326\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5755506353378297\n",
      "\n",
      "Epoch:   18/30    Loss: 3.500513659477234\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5511171588897703\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5891112117767334\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5519186563491822\n",
      "\n",
      "Epoch:   18/30    Loss: 3.543347403049469\n",
      "\n",
      "Epoch:   18/30    Loss: 3.56676113653183\n",
      "\n",
      "Epoch:   18/30    Loss: 3.563517255783081\n",
      "\n",
      "Epoch:   18/30    Loss: 3.56848161649704\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5274426183700562\n",
      "\n",
      "Epoch:   18/30    Loss: 3.589191830635071\n",
      "\n",
      "Epoch:   18/30    Loss: 3.6025423345565795\n",
      "\n",
      "Epoch:   18/30    Loss: 3.597199098587036\n",
      "\n",
      "Epoch:   18/30    Loss: 3.584729994058609\n",
      "\n",
      "Epoch:   18/30    Loss: 3.5543576445579528\n",
      "\n",
      "Epoch:   18/30    Loss: 3.560396806716919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████▍                             | 18/30 [26:41:57<17:50:28, 5352.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   19/30    Loss: 3.4876260070431475\n",
      "\n",
      "Epoch:   19/30    Loss: 3.3417204723358154\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4172073078155516\n",
      "\n",
      "Epoch:   19/30    Loss: 3.3691905660629273\n",
      "\n",
      "Epoch:   19/30    Loss: 3.375296088695526\n",
      "\n",
      "Epoch:   19/30    Loss: 3.389170539855957\n",
      "\n",
      "Epoch:   19/30    Loss: 3.416462819337845\n",
      "\n",
      "Epoch:   19/30    Loss: 3.435761781692505\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4132292504310606\n",
      "\n",
      "Epoch:   19/30    Loss: 3.3946187543869017\n",
      "\n",
      "Epoch:   19/30    Loss: 3.434032935619354\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4430732588768005\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4238719606399535\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4709075632095336\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4546587450504305\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4412842202186584\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4448587012290957\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4467982585430144\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4784765129089354\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4512993733882906\n",
      "\n",
      "Epoch:   19/30    Loss: 3.436617733955383\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4344070458412173\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4665176391601564\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5072684721946716\n",
      "\n",
      "Epoch:   19/30    Loss: 3.476889234542847\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5045665926933287\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4911544013023375\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5098731641769407\n",
      "\n",
      "Epoch:   19/30    Loss: 3.500284725189209\n",
      "\n",
      "Epoch:   19/30    Loss: 3.487609541654587\n",
      "\n",
      "Epoch:   19/30    Loss: 3.528543689250946\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5113470249176024\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5065728597640993\n",
      "\n",
      "Epoch:   19/30    Loss: 3.4620447359085085\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5530054669380187\n",
      "\n",
      "Epoch:   19/30    Loss: 3.518931495189667\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5470782408714294\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5183869857788084\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5096804604530334\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5616235628128052\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5563632507324217\n",
      "\n",
      "Epoch:   19/30    Loss: 3.550458547115326\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5466073484420777\n",
      "\n",
      "Epoch:   19/30    Loss: 3.562041983604431\n",
      "\n",
      "Epoch:   19/30    Loss: 3.517187601566315\n",
      "\n",
      "Epoch:   19/30    Loss: 3.533059187412262\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5755559821128844\n",
      "\n",
      "Epoch:   19/30    Loss: 3.586826873540878\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5459027729034425\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5562785682678224\n",
      "\n",
      "Epoch:   19/30    Loss: 3.546928166389465\n",
      "\n",
      "Epoch:   19/30    Loss: 3.583063925743103\n",
      "\n",
      "Epoch:   19/30    Loss: 3.518980453491211\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5471400880813597\n",
      "\n",
      "Epoch:   19/30    Loss: 3.5615022258758544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████▊                           | 19/30 [28:11:35<16:22:41, 5360.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   20/30    Loss: 3.4504107443238174\n",
      "\n",
      "Epoch:   20/30    Loss: 3.3526749844551085\n",
      "\n",
      "Epoch:   20/30    Loss: 3.353186328649521\n",
      "\n",
      "Epoch:   20/30    Loss: 3.342567620754242\n",
      "\n",
      "Epoch:   20/30    Loss: 3.3704904747009277\n",
      "\n",
      "Epoch:   20/30    Loss: 3.374937180519104\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4052180726528167\n",
      "\n",
      "Epoch:   20/30    Loss: 3.389678862094879\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4311489615440367\n",
      "\n",
      "Epoch:   20/30    Loss: 3.3507780685424806\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4507070422172545\n",
      "\n",
      "Epoch:   20/30    Loss: 3.429751082420349\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4585830698013305\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4494056413173677\n",
      "\n",
      "Epoch:   20/30    Loss: 3.43667506980896\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4893080520629884\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4144874310493467\n",
      "\n",
      "Epoch:   20/30    Loss: 3.3964517362117768\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4509296972751615\n",
      "\n",
      "Epoch:   20/30    Loss: 3.439791058778763\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4797667350769044\n",
      "\n",
      "Epoch:   20/30    Loss: 3.461378242969513\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5011142060756684\n",
      "\n",
      "Epoch:   20/30    Loss: 3.462047361135483\n",
      "\n",
      "Epoch:   20/30    Loss: 3.502631628513336\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5023164360523222\n",
      "\n",
      "Epoch:   20/30    Loss: 3.463454009771347\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4363267011642455\n",
      "\n",
      "Epoch:   20/30    Loss: 3.49199799823761\n",
      "\n",
      "Epoch:   20/30    Loss: 3.497666437149048\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4660669960975645\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4842519245147705\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4679766025543213\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4871820425987243\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5093928661346436\n",
      "\n",
      "Epoch:   20/30    Loss: 3.515563899040222\n",
      "\n",
      "Epoch:   20/30    Loss: 3.4761529529094695\n",
      "\n",
      "Epoch:   20/30    Loss: 3.551593948841095\n",
      "\n",
      "Epoch:   20/30    Loss: 3.533569941997528\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5240387954711916\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5559075372219087\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5350686738491057\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5060262837409972\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5276141228675844\n",
      "\n",
      "Epoch:   20/30    Loss: 3.561492775917053\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5219397654533386\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5220426092147825\n",
      "\n",
      "Epoch:   20/30    Loss: 3.570605727672577\n",
      "\n",
      "Epoch:   20/30    Loss: 3.562964102268219\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5394381852149963\n",
      "\n",
      "Epoch:   20/30    Loss: 3.564704710483551\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5683268537521364\n",
      "\n",
      "Epoch:   20/30    Loss: 3.602239051818848\n",
      "\n",
      "Epoch:   20/30    Loss: 3.5227882301807405\n",
      "\n",
      "Epoch:   20/30    Loss: 3.562031219959259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████▎                        | 20/30 [29:41:16<14:54:22, 5366.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   21/30    Loss: 3.421837375348684\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3539188385009764\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3809304106235505\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3261850819587706\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3792419617176055\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3543215243816378\n",
      "\n",
      "Epoch:   21/30    Loss: 3.382378939151764\n",
      "\n",
      "Epoch:   21/30    Loss: 3.372267022609711\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4233093953132627\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4027518112659454\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4531687335968018\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3628359942436217\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3993677620887754\n",
      "\n",
      "Epoch:   21/30    Loss: 3.40705034828186\n",
      "\n",
      "Epoch:   21/30    Loss: 3.442612466812134\n",
      "\n",
      "Epoch:   21/30    Loss: 3.443507504463196\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4424020276069642\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4702579464912415\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4537412359714508\n",
      "\n",
      "Epoch:   21/30    Loss: 3.3989776396751403\n",
      "\n",
      "Epoch:   21/30    Loss: 3.436318125009537\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4685354228019714\n",
      "\n",
      "Epoch:   21/30    Loss: 3.403449878692627\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4403850569725036\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4582949624061583\n",
      "\n",
      "Epoch:   21/30    Loss: 3.430993176937103\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4827185847759248\n",
      "\n",
      "Epoch:   21/30    Loss: 3.512342029094696\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4580402331352236\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4992736382484435\n",
      "\n",
      "Epoch:   21/30    Loss: 3.462448131799698\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5173333501815796\n",
      "\n",
      "Epoch:   21/30    Loss: 3.480780378103256\n",
      "\n",
      "Epoch:   21/30    Loss: 3.517075393676758\n",
      "\n",
      "Epoch:   21/30    Loss: 3.508957596540451\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4977450869083406\n",
      "\n",
      "Epoch:   21/30    Loss: 3.512165517091751\n",
      "\n",
      "Epoch:   21/30    Loss: 3.495211980819702\n",
      "\n",
      "Epoch:   21/30    Loss: 3.523618347406387\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4970985229015352\n",
      "\n",
      "Epoch:   21/30    Loss: 3.4902719733715055\n",
      "\n",
      "Epoch:   21/30    Loss: 3.532601390361786\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5413330702781676\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5091617596149445\n",
      "\n",
      "Epoch:   21/30    Loss: 3.516239562749863\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5394020833969115\n",
      "\n",
      "Epoch:   21/30    Loss: 3.541380969285965\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5464027881622315\n",
      "\n",
      "Epoch:   21/30    Loss: 3.49090326499939\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5211864733695983\n",
      "\n",
      "Epoch:   21/30    Loss: 3.55564710521698\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5796066455841062\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5558925848007203\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5468314666748046\n",
      "\n",
      "Epoch:   21/30    Loss: 3.5839782419204713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████▊                      | 21/30 [31:10:52<13:25:21, 5369.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   22/30    Loss: 3.427038501362594\n",
      "\n",
      "Epoch:   22/30    Loss: 3.342295486688614\n",
      "\n",
      "Epoch:   22/30    Loss: 3.308832249403\n",
      "\n",
      "Epoch:   22/30    Loss: 3.302105356693268\n",
      "\n",
      "Epoch:   22/30    Loss: 3.3725301127433776\n",
      "\n",
      "Epoch:   22/30    Loss: 3.388005329608917\n",
      "\n",
      "Epoch:   22/30    Loss: 3.358915558338165\n",
      "\n",
      "Epoch:   22/30    Loss: 3.371544242143631\n",
      "\n",
      "Epoch:   22/30    Loss: 3.3979338274002076\n",
      "\n",
      "Epoch:   22/30    Loss: 3.375303159713745\n",
      "\n",
      "Epoch:   22/30    Loss: 3.3861022906303404\n",
      "\n",
      "Epoch:   22/30    Loss: 3.429108428478241\n",
      "\n",
      "Epoch:   22/30    Loss: 3.3733352587223053\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4052297611236573\n",
      "\n",
      "Epoch:   22/30    Loss: 3.3869788491725923\n",
      "\n",
      "Epoch:   22/30    Loss: 3.392819365978241\n",
      "\n",
      "Epoch:   22/30    Loss: 3.430481077194214\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4128782992362976\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4411080548763273\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4113539187908173\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4191839294433595\n",
      "\n",
      "Epoch:   22/30    Loss: 3.438901349067688\n",
      "\n",
      "Epoch:   22/30    Loss: 3.434113862514496\n",
      "\n",
      "Epoch:   22/30    Loss: 3.453331517457962\n",
      "\n",
      "Epoch:   22/30    Loss: 3.48663067317009\n",
      "\n",
      "Epoch:   22/30    Loss: 3.427313817501068\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4470929341316223\n",
      "\n",
      "Epoch:   22/30    Loss: 3.492584969043732\n",
      "\n",
      "Epoch:   22/30    Loss: 3.480711374282837\n",
      "\n",
      "Epoch:   22/30    Loss: 3.504591958999634\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4670508863925935\n",
      "\n",
      "Epoch:   22/30    Loss: 3.485217689037323\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4801497986316683\n",
      "\n",
      "Epoch:   22/30    Loss: 3.492060366868973\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4600189414024354\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4865497510433197\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5431437070369722\n",
      "\n",
      "Epoch:   22/30    Loss: 3.474280693292618\n",
      "\n",
      "Epoch:   22/30    Loss: 3.475525554180145\n",
      "\n",
      "Epoch:   22/30    Loss: 3.48286843585968\n",
      "\n",
      "Epoch:   22/30    Loss: 3.465718923330307\n",
      "\n",
      "Epoch:   22/30    Loss: 3.548099708080292\n",
      "\n",
      "Epoch:   22/30    Loss: 3.4796572468280793\n",
      "\n",
      "Epoch:   22/30    Loss: 3.526386971473694\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5467592306137083\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5388680872917173\n",
      "\n",
      "Epoch:   22/30    Loss: 3.565079330921173\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5068198685646057\n",
      "\n",
      "Epoch:   22/30    Loss: 3.536460054397583\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5541547861099243\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5600685510635377\n",
      "\n",
      "Epoch:   22/30    Loss: 3.576267773628235\n",
      "\n",
      "Epoch:   22/30    Loss: 3.53400101518631\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5758176198005676\n",
      "\n",
      "Epoch:   22/30    Loss: 3.5468776054382323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████▎                   | 22/30 [32:40:24<11:56:01, 5370.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   23/30    Loss: 3.3994893729007867\n",
      "\n",
      "Epoch:   23/30    Loss: 3.347331230163574\n",
      "\n",
      "Epoch:   23/30    Loss: 3.306737374305725\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3111287126541136\n",
      "\n",
      "Epoch:   23/30    Loss: 3.33030365395546\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3474967765808104\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3712593863010407\n",
      "\n",
      "Epoch:   23/30    Loss: 3.368210554122925\n",
      "\n",
      "Epoch:   23/30    Loss: 3.318718115568161\n",
      "\n",
      "Epoch:   23/30    Loss: 3.399663201332092\n",
      "\n",
      "Epoch:   23/30    Loss: 3.359062039375305\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3499642820358275\n",
      "\n",
      "Epoch:   23/30    Loss: 3.411625883102417\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3749223980903627\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4286313865184783\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3823756499290467\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4207711200714113\n",
      "\n",
      "Epoch:   23/30    Loss: 3.423768588066101\n",
      "\n",
      "Epoch:   23/30    Loss: 3.410774249076843\n",
      "\n",
      "Epoch:   23/30    Loss: 3.413380194425583\n",
      "\n",
      "Epoch:   23/30    Loss: 3.3950266971588134\n",
      "\n",
      "Epoch:   23/30    Loss: 3.405059161901474\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4421559920310973\n",
      "\n",
      "Epoch:   23/30    Loss: 3.436191201686859\n",
      "\n",
      "Epoch:   23/30    Loss: 3.444863529920578\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4667683811187744\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4273175582885744\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4789415349960326\n",
      "\n",
      "Epoch:   23/30    Loss: 3.508668481826782\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4735777678489685\n",
      "\n",
      "Epoch:   23/30    Loss: 3.449733196258545\n",
      "\n",
      "Epoch:   23/30    Loss: 3.499040155649185\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4076608052253725\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4356197605133056\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5049777443408967\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4637329335212708\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4606396641731263\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5131431460380553\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4924646229743956\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5268181691169738\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5114828844070436\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5044376435279845\n",
      "\n",
      "Epoch:   23/30    Loss: 3.513862428665161\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5277768349647523\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5174419898986815\n",
      "\n",
      "Epoch:   23/30    Loss: 3.572839309692383\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4827000799179078\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4989703831672667\n",
      "\n",
      "Epoch:   23/30    Loss: 3.582675513267517\n",
      "\n",
      "Epoch:   23/30    Loss: 3.47894936132431\n",
      "\n",
      "Epoch:   23/30    Loss: 3.4920058279037476\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5445204033851625\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5696421790122987\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5376587166786195\n",
      "\n",
      "Epoch:   23/30    Loss: 3.5435140352249146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████████████████████████████▋                 | 23/30 [34:09:54<10:26:30, 5370.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   24/30    Loss: 3.4343990580367607\n",
      "\n",
      "Epoch:   24/30    Loss: 3.321112889289856\n",
      "\n",
      "Epoch:   24/30    Loss: 3.309712921142578\n",
      "\n",
      "Epoch:   24/30    Loss: 3.2811190421581267\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3185653235912325\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3484724528789522\n",
      "\n",
      "Epoch:   24/30    Loss: 3.364593023777008\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3530162286758425\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3084494202136994\n",
      "\n",
      "Epoch:   24/30    Loss: 3.355837899684906\n",
      "\n",
      "Epoch:   24/30    Loss: 3.353188073158264\n",
      "\n",
      "Epoch:   24/30    Loss: 3.349035736083984\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3558021404743195\n",
      "\n",
      "Epoch:   24/30    Loss: 3.381989265203476\n",
      "\n",
      "Epoch:   24/30    Loss: 3.387815011024475\n",
      "\n",
      "Epoch:   24/30    Loss: 3.386434250831604\n",
      "\n",
      "Epoch:   24/30    Loss: 3.403816749095917\n",
      "\n",
      "Epoch:   24/30    Loss: 3.356646320581436\n",
      "\n",
      "Epoch:   24/30    Loss: 3.3769264059066773\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4411985099315645\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4085386555194854\n",
      "\n",
      "Epoch:   24/30    Loss: 3.411920816421509\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4252455387115477\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4333019256591797\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4864360461235044\n",
      "\n",
      "Epoch:   24/30    Loss: 3.457018617630005\n",
      "\n",
      "Epoch:   24/30    Loss: 3.426453230381012\n",
      "\n",
      "Epoch:   24/30    Loss: 3.468198437690735\n",
      "\n",
      "Epoch:   24/30    Loss: 3.426762156009674\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4608951296806336\n",
      "\n",
      "Epoch:   24/30    Loss: 3.432758722305298\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4481764435768127\n",
      "\n",
      "Epoch:   24/30    Loss: 3.469670681476593\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4894388184547425\n",
      "\n",
      "Epoch:   24/30    Loss: 3.478569068431854\n",
      "\n",
      "Epoch:   24/30    Loss: 3.493290638923645\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4866362144947054\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5086552469730377\n",
      "\n",
      "Epoch:   24/30    Loss: 3.456942305088043\n",
      "\n",
      "Epoch:   24/30    Loss: 3.514664001941681\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4822891688346864\n",
      "\n",
      "Epoch:   24/30    Loss: 3.492206883907318\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4738623394966126\n",
      "\n",
      "Epoch:   24/30    Loss: 3.464835610628128\n",
      "\n",
      "Epoch:   24/30    Loss: 3.51932227230072\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5263425960540773\n",
      "\n",
      "Epoch:   24/30    Loss: 3.507546754837036\n",
      "\n",
      "Epoch:   24/30    Loss: 3.550218723297119\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5242922716140748\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5288061304092406\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5505094799995423\n",
      "\n",
      "Epoch:   24/30    Loss: 3.556635107755661\n",
      "\n",
      "Epoch:   24/30    Loss: 3.5097862548828127\n",
      "\n",
      "Epoch:   24/30    Loss: 3.4950601592063903\n",
      "\n",
      "Epoch:   24/30    Loss: 3.531293522834778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████               | 24/30 [35:39:50<8:57:46, 5377.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   25/30    Loss: 3.4001930531173743\n",
      "\n",
      "Epoch:   25/30    Loss: 3.2918341681957246\n",
      "\n",
      "Epoch:   25/30    Loss: 3.305594274997711\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3556797842979433\n",
      "\n",
      "Epoch:   25/30    Loss: 3.333119748830795\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3129589757919313\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3112759721279144\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3447304594516756\n",
      "\n",
      "Epoch:   25/30    Loss: 3.358681361198425\n",
      "\n",
      "Epoch:   25/30    Loss: 3.362378664255142\n",
      "\n",
      "Epoch:   25/30    Loss: 3.33159504032135\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3524507851600647\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3882496368885042\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3916042602062224\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3511901733875273\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3840311467647552\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4071979081630706\n",
      "\n",
      "Epoch:   25/30    Loss: 3.3658592634201048\n",
      "\n",
      "Epoch:   25/30    Loss: 3.370341756820679\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4195637531280516\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4465287480354307\n",
      "\n",
      "Epoch:   25/30    Loss: 3.392221311092377\n",
      "\n",
      "Epoch:   25/30    Loss: 3.395782361984253\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4608916091918944\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4169518349170684\n",
      "\n",
      "Epoch:   25/30    Loss: 3.416635026931763\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4090378501415253\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4382670607566834\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4448742887973784\n",
      "\n",
      "Epoch:   25/30    Loss: 3.451271911621094\n",
      "\n",
      "Epoch:   25/30    Loss: 3.465587284564972\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4416586413383485\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4649016289711\n",
      "\n",
      "Epoch:   25/30    Loss: 3.407015538454056\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4390435411930085\n",
      "\n",
      "Epoch:   25/30    Loss: 3.453980616569519\n",
      "\n",
      "Epoch:   25/30    Loss: 3.5009080114364624\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4636637811660766\n",
      "\n",
      "Epoch:   25/30    Loss: 3.5049210896492005\n",
      "\n",
      "Epoch:   25/30    Loss: 3.390745869398117\n",
      "\n",
      "Epoch:   25/30    Loss: 3.46299293422699\n",
      "\n",
      "Epoch:   25/30    Loss: 3.458455544471741\n",
      "\n",
      "Epoch:   25/30    Loss: 3.503462832927704\n",
      "\n",
      "Epoch:   25/30    Loss: 3.516948389530182\n",
      "\n",
      "Epoch:   25/30    Loss: 3.506891295671463\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4981093292236327\n",
      "\n",
      "Epoch:   25/30    Loss: 3.5424168815612793\n",
      "\n",
      "Epoch:   25/30    Loss: 3.4844430174827576\n",
      "\n",
      "Epoch:   25/30    Loss: 3.479629850625992\n",
      "\n",
      "Epoch:   25/30    Loss: 3.51485488986969\n",
      "\n",
      "Epoch:   25/30    Loss: 3.5240568451881407\n",
      "\n",
      "Epoch:   25/30    Loss: 3.478993235588074\n",
      "\n",
      "Epoch:   25/30    Loss: 3.547397856712341\n",
      "\n",
      "Epoch:   25/30    Loss: 3.5514570546150206\n",
      "\n",
      "Epoch:   25/30    Loss: 3.484089153289795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████▌            | 25/30 [37:09:50<7:28:41, 5384.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   26/30    Loss: 3.397156268697665\n",
      "\n",
      "Epoch:   26/30    Loss: 3.2592350480556487\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3055154950618744\n",
      "\n",
      "Epoch:   26/30    Loss: 3.302775602579117\n",
      "\n",
      "Epoch:   26/30    Loss: 3.315145703077316\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3396475207805634\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3213983812332155\n",
      "\n",
      "Epoch:   26/30    Loss: 3.290772691488266\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3554972281455995\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3515429220199584\n",
      "\n",
      "Epoch:   26/30    Loss: 3.340215461969376\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3627286431789396\n",
      "\n",
      "Epoch:   26/30    Loss: 3.331478946208954\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3602652432918547\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3509141492843626\n",
      "\n",
      "Epoch:   26/30    Loss: 3.380034104824066\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4123313884735107\n",
      "\n",
      "Epoch:   26/30    Loss: 3.3650749740600587\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4482950949668885\n",
      "\n",
      "Epoch:   26/30    Loss: 3.418680516242981\n",
      "\n",
      "Epoch:   26/30    Loss: 3.412179736852646\n",
      "\n",
      "Epoch:   26/30    Loss: 3.372924340724945\n",
      "\n",
      "Epoch:   26/30    Loss: 3.413385993719101\n",
      "\n",
      "Epoch:   26/30    Loss: 3.341782392501831\n",
      "\n",
      "Epoch:   26/30    Loss: 3.372236789703369\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4237822086811067\n",
      "\n",
      "Epoch:   26/30    Loss: 3.433297311782837\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4524986183643342\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4363610215187075\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4125988168716432\n",
      "\n",
      "Epoch:   26/30    Loss: 3.454682233095169\n",
      "\n",
      "Epoch:   26/30    Loss: 3.510751699209213\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4217138724327087\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4720709409713746\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4766310181617737\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4780985085964202\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4008856554031373\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4301171443462373\n",
      "\n",
      "Epoch:   26/30    Loss: 3.471269791841507\n",
      "\n",
      "Epoch:   26/30    Loss: 3.496071916103363\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4447312700748443\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4073928451538085\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4231474578380583\n",
      "\n",
      "Epoch:   26/30    Loss: 3.458999029159546\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4486761660575866\n",
      "\n",
      "Epoch:   26/30    Loss: 3.516763480424881\n",
      "\n",
      "Epoch:   26/30    Loss: 3.4450458614826203\n",
      "\n",
      "Epoch:   26/30    Loss: 3.485386061668396\n",
      "\n",
      "Epoch:   26/30    Loss: 3.5429731504917146\n",
      "\n",
      "Epoch:   26/30    Loss: 3.5327275543212893\n",
      "\n",
      "Epoch:   26/30    Loss: 3.583793495416641\n",
      "\n",
      "Epoch:   26/30    Loss: 3.5167785444259643\n",
      "\n",
      "Epoch:   26/30    Loss: 3.5105129461288453\n",
      "\n",
      "Epoch:   26/30    Loss: 3.464883053064346\n",
      "\n",
      "Epoch:   26/30    Loss: 3.495626059770584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████          | 26/30 [38:39:16<5:58:35, 5378.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   27/30    Loss: 3.3534653934911063\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3245227565765383\n",
      "\n",
      "Epoch:   27/30    Loss: 3.2812533071041106\n",
      "\n",
      "Epoch:   27/30    Loss: 3.304499442100525\n",
      "\n",
      "Epoch:   27/30    Loss: 3.303352928876877\n",
      "\n",
      "Epoch:   27/30    Loss: 3.2905447189807893\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3408980088233946\n",
      "\n",
      "Epoch:   27/30    Loss: 3.351658266544342\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3768572661876677\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3238731718063352\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3406588077545165\n",
      "\n",
      "Epoch:   27/30    Loss: 3.2999372284412383\n",
      "\n",
      "Epoch:   27/30    Loss: 3.320055802345276\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3489220111370086\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3496448414325712\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3335462288856506\n",
      "\n",
      "Epoch:   27/30    Loss: 3.389539507865906\n",
      "\n",
      "Epoch:   27/30    Loss: 3.386184163570404\n",
      "\n",
      "Epoch:   27/30    Loss: 3.3867874479293825\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4140988776683807\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4228827023506163\n",
      "\n",
      "Epoch:   27/30    Loss: 3.427092505931854\n",
      "\n",
      "Epoch:   27/30    Loss: 3.432199013233185\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4368487071990965\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4402929005622864\n",
      "\n",
      "Epoch:   27/30    Loss: 3.409286384820938\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4277666053771974\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4196841387748718\n",
      "\n",
      "Epoch:   27/30    Loss: 3.380392331123352\n",
      "\n",
      "Epoch:   27/30    Loss: 3.451284091949463\n",
      "\n",
      "Epoch:   27/30    Loss: 3.412810042619705\n",
      "\n",
      "Epoch:   27/30    Loss: 3.397970445871353\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4238377337455748\n",
      "\n",
      "Epoch:   27/30    Loss: 3.45100101351738\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4525598440170286\n",
      "\n",
      "Epoch:   27/30    Loss: 3.451212537288666\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4191375999450684\n",
      "\n",
      "Epoch:   27/30    Loss: 3.434380368947983\n",
      "\n",
      "Epoch:   27/30    Loss: 3.446535439491272\n",
      "\n",
      "Epoch:   27/30    Loss: 3.459591031074524\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4281790232658387\n",
      "\n",
      "Epoch:   27/30    Loss: 3.459292091846466\n",
      "\n",
      "Epoch:   27/30    Loss: 3.435583500146866\n",
      "\n",
      "Epoch:   27/30    Loss: 3.50757066822052\n",
      "\n",
      "Epoch:   27/30    Loss: 3.451977149963379\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4574258697032927\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4075111410617827\n",
      "\n",
      "Epoch:   27/30    Loss: 3.442689164161682\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4647911863327026\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4983353195190428\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4993112969398497\n",
      "\n",
      "Epoch:   27/30    Loss: 3.4218448593616486\n",
      "\n",
      "Epoch:   27/30    Loss: 3.471882716655731\n",
      "\n",
      "Epoch:   27/30    Loss: 3.5123273005485536\n",
      "\n",
      "Epoch:   27/30    Loss: 3.5227441425323485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████▌       | 27/30 [40:09:00<4:29:01, 5380.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   28/30    Loss: 3.368641329653442\n",
      "\n",
      "Epoch:   28/30    Loss: 3.2805127098560334\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3464299037456513\n",
      "\n",
      "Epoch:   28/30    Loss: 3.257939736366272\n",
      "\n",
      "Epoch:   28/30    Loss: 3.2711611530780793\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3220822863578796\n",
      "\n",
      "Epoch:   28/30    Loss: 3.2911878542900084\n",
      "\n",
      "Epoch:   28/30    Loss: 3.316091423034668\n",
      "\n",
      "Epoch:   28/30    Loss: 3.346722625732422\n",
      "\n",
      "Epoch:   28/30    Loss: 3.2987579207420348\n",
      "\n",
      "Epoch:   28/30    Loss: 3.332475743293762\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3056834630966185\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3496679153442384\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3121408874988556\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3417722964286805\n",
      "\n",
      "Epoch:   28/30    Loss: 3.328845205068588\n",
      "\n",
      "Epoch:   28/30    Loss: 3.375286849975586\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3664296140670777\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3259941956996917\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3873672552108767\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3849493539333344\n",
      "\n",
      "Epoch:   28/30    Loss: 3.356431839466095\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4084885330200194\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3298267352581026\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3802556464672087\n",
      "\n",
      "Epoch:   28/30    Loss: 3.402942171096802\n",
      "\n",
      "Epoch:   28/30    Loss: 3.399244200229645\n",
      "\n",
      "Epoch:   28/30    Loss: 3.416066283226013\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4482864427566526\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4009146089553832\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4140564897060393\n",
      "\n",
      "Epoch:   28/30    Loss: 3.3768501987457276\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4179501938819885\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4177417504787444\n",
      "\n",
      "Epoch:   28/30    Loss: 3.438319191932678\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4020708582401276\n",
      "\n",
      "Epoch:   28/30    Loss: 3.467352576255798\n",
      "\n",
      "Epoch:   28/30    Loss: 3.411985625267029\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4224651107788087\n",
      "\n",
      "Epoch:   28/30    Loss: 3.393269420146942\n",
      "\n",
      "Epoch:   28/30    Loss: 3.458404869556427\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4839444127082824\n",
      "\n",
      "Epoch:   28/30    Loss: 3.434660242319107\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4408328523635863\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4994432168006897\n",
      "\n",
      "Epoch:   28/30    Loss: 3.450056452512741\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4852569856643676\n",
      "\n",
      "Epoch:   28/30    Loss: 3.449483746051788\n",
      "\n",
      "Epoch:   28/30    Loss: 3.454617147922516\n",
      "\n",
      "Epoch:   28/30    Loss: 3.452150495052338\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4797835233211516\n",
      "\n",
      "Epoch:   28/30    Loss: 3.493791758775711\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4627328615188597\n",
      "\n",
      "Epoch:   28/30    Loss: 3.497685319185257\n",
      "\n",
      "Epoch:   28/30    Loss: 3.4845185310840607\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████     | 28/30 [41:38:42<2:59:21, 5380.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   29/30    Loss: 3.358306271883241\n",
      "\n",
      "Epoch:   29/30    Loss: 3.238641005754471\n",
      "\n",
      "Epoch:   29/30    Loss: 3.27620326089859\n",
      "\n",
      "Epoch:   29/30    Loss: 3.285249485731125\n",
      "\n",
      "Epoch:   29/30    Loss: 3.2541409142017366\n",
      "\n",
      "Epoch:   29/30    Loss: 3.2915873465538024\n",
      "\n",
      "Epoch:   29/30    Loss: 3.2716327471733093\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3077684829235077\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3378350074291228\n",
      "\n",
      "Epoch:   29/30    Loss: 3.281961927652359\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3055741658210755\n",
      "\n",
      "Epoch:   29/30    Loss: 3.302669280529022\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3171240990161897\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3464309134483337\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3442230968475344\n",
      "\n",
      "Epoch:   29/30    Loss: 3.338314121723175\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3245060505867006\n",
      "\n",
      "Epoch:   29/30    Loss: 3.349236986160278\n",
      "\n",
      "Epoch:   29/30    Loss: 3.371635474205017\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3510051505565643\n",
      "\n",
      "Epoch:   29/30    Loss: 3.403738645553589\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3795646941661834\n",
      "\n",
      "Epoch:   29/30    Loss: 3.354976163625717\n",
      "\n",
      "Epoch:   29/30    Loss: 3.350030869245529\n",
      "\n",
      "Epoch:   29/30    Loss: 3.389457248210907\n",
      "\n",
      "Epoch:   29/30    Loss: 3.403930640935898\n",
      "\n",
      "Epoch:   29/30    Loss: 3.370713974237442\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3995573518276214\n",
      "\n",
      "Epoch:   29/30    Loss: 3.338786061048508\n",
      "\n",
      "Epoch:   29/30    Loss: 3.417889214992523\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4075590713024138\n",
      "\n",
      "Epoch:   29/30    Loss: 3.392345098733902\n",
      "\n",
      "Epoch:   29/30    Loss: 3.407355597734451\n",
      "\n",
      "Epoch:   29/30    Loss: 3.41151953458786\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4427306613922117\n",
      "\n",
      "Epoch:   29/30    Loss: 3.41873850440979\n",
      "\n",
      "Epoch:   29/30    Loss: 3.452898386478424\n",
      "\n",
      "Epoch:   29/30    Loss: 3.409352633714676\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4232912707328795\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4806500115394594\n",
      "\n",
      "Epoch:   29/30    Loss: 3.421826382637024\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4401881647109986\n",
      "\n",
      "Epoch:   29/30    Loss: 3.463619324207306\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4364157657623293\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4450792136192323\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4255813195705413\n",
      "\n",
      "Epoch:   29/30    Loss: 3.418965394496918\n",
      "\n",
      "Epoch:   29/30    Loss: 3.408494505405426\n",
      "\n",
      "Epoch:   29/30    Loss: 3.3924766557216643\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4639949669837953\n",
      "\n",
      "Epoch:   29/30    Loss: 3.455399198055267\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4570302612781525\n",
      "\n",
      "Epoch:   29/30    Loss: 3.490721333503723\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4528732299804688\n",
      "\n",
      "Epoch:   29/30    Loss: 3.4945212030410766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|████████████████████████████████████████████████████████████████████████▌  | 29/30 [43:07:44<1:29:29, 5369.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   30/30    Loss: 3.3507579282638966\n",
      "\n",
      "Epoch:   30/30    Loss: 3.2819102745056155\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3065697944164274\n",
      "\n",
      "Epoch:   30/30    Loss: 3.268867141723633\n",
      "\n",
      "Epoch:   30/30    Loss: 3.280075402498245\n",
      "\n",
      "Epoch:   30/30    Loss: 3.2668852715492247\n",
      "\n",
      "Epoch:   30/30    Loss: 3.287214071273804\n",
      "\n",
      "Epoch:   30/30    Loss: 3.2565506172180174\n",
      "\n",
      "Epoch:   30/30    Loss: 3.280714129924774\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3060995745658874\n",
      "\n",
      "Epoch:   30/30    Loss: 3.349662329673767\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3313460311889647\n",
      "\n",
      "Epoch:   30/30    Loss: 3.286267727136612\n",
      "\n",
      "Epoch:   30/30    Loss: 3.315082930326462\n",
      "\n",
      "Epoch:   30/30    Loss: 3.319010198354721\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3348175873756407\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3184071786403657\n",
      "\n",
      "Epoch:   30/30    Loss: 3.276852245807648\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3334936633110046\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3593792395591735\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3554242124557496\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3976867225170135\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3731057317256927\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3486917555332183\n",
      "\n",
      "Epoch:   30/30    Loss: 3.350641453027725\n",
      "\n",
      "Epoch:   30/30    Loss: 3.346937327623367\n",
      "\n",
      "Epoch:   30/30    Loss: 3.388498705863953\n",
      "\n",
      "Epoch:   30/30    Loss: 3.36121080160141\n",
      "\n",
      "Epoch:   30/30    Loss: 3.383792691230774\n",
      "\n",
      "Epoch:   30/30    Loss: 3.386044094324112\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4354515120983122\n",
      "\n",
      "Epoch:   30/30    Loss: 3.363428416967392\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3360438632965086\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3774039595127108\n",
      "\n",
      "Epoch:   30/30    Loss: 3.404645122528076\n",
      "\n",
      "Epoch:   30/30    Loss: 3.403732797384262\n",
      "\n",
      "Epoch:   30/30    Loss: 3.396488021850586\n",
      "\n",
      "Epoch:   30/30    Loss: 3.40481640291214\n",
      "\n",
      "Epoch:   30/30    Loss: 3.407857882738113\n",
      "\n",
      "Epoch:   30/30    Loss: 3.3559626183509828\n",
      "\n",
      "Epoch:   30/30    Loss: 3.420585994720459\n",
      "\n",
      "Epoch:   30/30    Loss: 3.443215103626251\n",
      "\n",
      "Epoch:   30/30    Loss: 3.435490217924118\n",
      "\n",
      "Epoch:   30/30    Loss: 3.436973002433777\n",
      "\n",
      "Epoch:   30/30    Loss: 3.406083606958389\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4374222679138184\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4486489629745485\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4348699905872344\n",
      "\n",
      "Epoch:   30/30    Loss: 3.435497839689255\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4279112319946288\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4317042841911314\n",
      "\n",
      "Epoch:   30/30    Loss: 3.453390089035034\n",
      "\n",
      "Epoch:   30/30    Loss: 3.4616663606166838\n",
      "\n",
      "Epoch:   30/30    Loss: 3.467247806072235\n",
      "\n",
      "Epoch:   30/30    Loss: 3.51050670003891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [44:36:52<00:00, 5353.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training the model\n",
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained model\n",
    "helper.save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue training :(\n",
    "\n",
    "# save states \n",
    "state = {'epoch': num_epochs + 1, 'state_dict': trained_rnn.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()}\n",
    "\n",
    "filename = 'trained30_rnn.pt'\n",
    "torch.save(state, filename)\n",
    "\n",
    "model = rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename):\n",
    "    '''\n",
    "    Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    '''\n",
    "    start_epoch = 0\n",
    "    checkpoint = torch.load(filename)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "model, opt, start_epoch = load_checkpoint(model, optimizer, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epoch(s)...\n",
      "Epoch:    1/2     Loss: 3.230847548723221\n",
      "\n",
      "Epoch:    1/2     Loss: 3.242536901950836\n",
      "\n",
      "Epoch:    1/2     Loss: 3.226005310535431\n",
      "\n",
      "Epoch:    1/2     Loss: 3.284716125488281\n",
      "\n",
      "Epoch:    1/2     Loss: 3.238082037448883\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2779522089958193\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2803900933265684\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2567694537639618\n",
      "\n",
      "Epoch:    1/2     Loss: 3.230153357028961\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2203620710372927\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2418822095394133\n",
      "\n",
      "Epoch:    1/2     Loss: 3.246777020454407\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2307465674877167\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2492629382610323\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2557648549079894\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2403375010490416\n",
      "\n",
      "Epoch:    1/2     Loss: 3.220504664182663\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2442013556957243\n",
      "\n",
      "Epoch:    1/2     Loss: 3.238982215166092\n",
      "\n",
      "Epoch:    1/2     Loss: 3.236511000394821\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2021658787727354\n",
      "\n",
      "Epoch:    1/2     Loss: 3.266299452781677\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2249232058525084\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2491437835693358\n",
      "\n",
      "Epoch:    1/2     Loss: 3.260394054889679\n",
      "\n",
      "Epoch:    1/2     Loss: 3.220214374780655\n",
      "\n",
      "Epoch:    1/2     Loss: 3.234553696155548\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2043969855308534\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2696939034461976\n",
      "\n",
      "Epoch:    1/2     Loss: 3.236947517633438\n",
      "\n",
      "Epoch:    1/2     Loss: 3.245328350305557\n",
      "\n",
      "Epoch:    1/2     Loss: 3.275922231912613\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2149587824344636\n",
      "\n",
      "Epoch:    1/2     Loss: 3.28770317029953\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2138376142978666\n",
      "\n",
      "Epoch:    1/2     Loss: 3.257383456945419\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2381991591453554\n",
      "\n",
      "Epoch:    1/2     Loss: 3.237292587995529\n",
      "\n",
      "Epoch:    1/2     Loss: 3.214402874946594\n",
      "\n",
      "Epoch:    1/2     Loss: 3.236719349384308\n",
      "\n",
      "Epoch:    1/2     Loss: 3.237342036485672\n",
      "\n",
      "Epoch:    1/2     Loss: 3.253374651670456\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2673941316604616\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2425915319919585\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2062871372699737\n",
      "\n",
      "Epoch:    1/2     Loss: 3.25836777305603\n",
      "\n",
      "Epoch:    1/2     Loss: 3.219010009288788\n",
      "\n",
      "Epoch:    1/2     Loss: 3.198156132936478\n",
      "\n",
      "Epoch:    1/2     Loss: 3.249026733636856\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2265054206848145\n",
      "\n",
      "Epoch:    1/2     Loss: 3.241127648115158\n",
      "\n",
      "Epoch:    1/2     Loss: 3.248390353679657\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2474790668487548\n",
      "\n",
      "Epoch:    1/2     Loss: 3.25672256231308\n",
      "\n",
      "Epoch:    1/2     Loss: 3.2418760097026826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████▌                                      | 1/2 [3:28:03<3:28:03, 12483.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/2     Loss: 3.235151591224931\n",
      "\n",
      "Epoch:    2/2     Loss: 3.233255350112915\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2245744981765747\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2616281716823576\n",
      "\n",
      "Epoch:    2/2     Loss: 3.213267842292786\n",
      "\n",
      "Epoch:    2/2     Loss: 3.20316557598114\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2736718525886537\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2411373143196105\n",
      "\n",
      "Epoch:    2/2     Loss: 3.25697576880455\n",
      "\n",
      "Epoch:    2/2     Loss: 3.246842366218567\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2621957981586456\n",
      "\n",
      "Epoch:    2/2     Loss: 3.1940839657783506\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2663290660381317\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2394476187229158\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2552397892475127\n",
      "\n",
      "Epoch:    2/2     Loss: 3.265643047809601\n",
      "\n",
      "Epoch:    2/2     Loss: 3.268998483419418\n",
      "\n",
      "Epoch:    2/2     Loss: 3.219040473937988\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2335102310180663\n",
      "\n",
      "Epoch:    2/2     Loss: 3.236566183805466\n",
      "\n",
      "Epoch:    2/2     Loss: 3.257062754154205\n",
      "\n",
      "Epoch:    2/2     Loss: 3.288965368747711\n",
      "\n",
      "Epoch:    2/2     Loss: 3.235949367046356\n",
      "\n",
      "Epoch:    2/2     Loss: 3.210952664613724\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2459170935153963\n",
      "\n",
      "Epoch:    2/2     Loss: 3.242525477409363\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2366565251350403\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2399108507633207\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2469271025657656\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2499736604690552\n",
      "\n",
      "Epoch:    2/2     Loss: 3.240253646850586\n",
      "\n",
      "Epoch:    2/2     Loss: 3.204586652517319\n",
      "\n",
      "Epoch:    2/2     Loss: 3.247456828117371\n",
      "\n",
      "Epoch:    2/2     Loss: 3.21458727145195\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2298471879959108\n",
      "\n",
      "Epoch:    2/2     Loss: 3.251167101383209\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2388186972141266\n",
      "\n",
      "Epoch:    2/2     Loss: 3.198498898029327\n",
      "\n",
      "Epoch:    2/2     Loss: 3.1974276397228243\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2433697905540466\n",
      "\n",
      "Epoch:    2/2     Loss: 3.265464675664902\n",
      "\n",
      "Epoch:    2/2     Loss: 3.226650053024292\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2740040431022646\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2267097260951996\n",
      "\n",
      "Epoch:    2/2     Loss: 3.234815535068512\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2549352531433104\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2365512900352478\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2168156833648682\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2794651708602904\n",
      "\n",
      "Epoch:    2/2     Loss: 3.211632086992264\n",
      "\n",
      "Epoch:    2/2     Loss: 3.228503740787506\n",
      "\n",
      "Epoch:    2/2     Loss: 3.255548601388931\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2294526615142822\n",
      "\n",
      "Epoch:    2/2     Loss: 3.224676746368408\n",
      "\n",
      "Epoch:    2/2     Loss: 3.2551480638980865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [7:01:05<00:00, 12632.90s/it]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu' # avoiding device erros\n",
    "model = model.to(device)\n",
    "# now individually transfer the optimizer parts...\n",
    "for state in opt.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "            \n",
    "# training the model\n",
    "model = train_rnn(model, batch_size, opt, criterion, 2, show_every_n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'epoch': 33, 'state_dict': model.state_dict(), 'optimizer': opt.state_dict()}\n",
    "\n",
    "filename = 'trained_rnn32.pt'\n",
    "torch.save(state, filename)\n",
    "helper.save_model('./save/trained_rnn', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How did you decide on your model hyperparameters? \n",
    "For example, did you try different sequence_lengths and find that one size made the model converge faster? What about your hidden_dim and n_layers; how did you decide on those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (Write answer, here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Checkpoint\n",
    "\n",
    "After running the above training cell, your model will be saved by name, `trained_rnn`, and if you save your notebook progress, **you can pause here and come back to this code at another time**. You can resume your progress by running the next cell, which will load in our word:id dictionaries _and_ load in your saved model by name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "trained_rnn = helper.load_model('./save/trained_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "With the network trained and saved, you'll use it to generate a new, \"fake\" Seinfeld TV script in this section.\n",
    "\n",
    "### Generate Text\n",
    "To generate the text, the network needs to start with a single word and repeat its predictions until it reaches a set length. You'll be using the `generate` function to do this. It takes a word id to start with, `prime_id`, and generates a set length of text, `predict_len`. Also note that it uses topk sampling to introduce some randomness in choosing the most likely next word, given an output set of word scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    \n",
    "    # create a sequence (batch_size=1) with the prime_id\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "#         if train_on_gpu:\n",
    "#             current_seq = torch.LongTensor(current_seq).cuda()\n",
    "#         else:\n",
    "        current_seq = torch.LongTensor(current_seq)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        hidden = [hid.to('cpu') for hid in hidden]\n",
    "       \n",
    "        # get the output of the rnn\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "         \n",
    "        # use top_k sampling to get the index of the next word\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next word index with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        \n",
    "        # retrieve that word from the dictionary\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)     \n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            current_seq = current_seq.cpu() # move to cpu\n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        if train_on_gpu:\n",
    "            current_seq = current_seq.cpu()\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    \n",
    "    # Replace punctuation tokens\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    \n",
    "    # return all the sentences\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a New Script\n",
    "It's time to generate the text. Set `gen_length` to the length of TV script you want to generate and set `prime_word` to one of the following to start the prediction:\n",
    "- \"jerry\"\n",
    "- \"elaine\"\n",
    "- \"george\"\n",
    "- \"kramer\"\n",
    "\n",
    "You can set the prime word to _any word_ in our dictionary, but it's best to start with a name for generating a TV script. (You can also start with any other names you find in the original text file!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newman: brody, i think we can get him out of here.\n",
      "\n",
      "jerry:(reading) gary fogel saw her dude cry.\n",
      "\n",
      "kramer: oh, you know what, let's go.\n",
      "\n",
      "jerry: oh, i can't believe i'm gonna get away from the subway!\n",
      "\n",
      "jerry: i don't think so.\n",
      "\n",
      "kramer: yeah, well.\n",
      "\n",
      "jerry: oh, no. no, i'm afraid i can't help him.\n",
      "\n",
      "jerry: well, you should see a doctor?\n",
      "\n",
      "kramer: yeah, i guess.\n",
      "\n",
      "elaine: i can't believe it, i can't believe this.\n",
      "\n",
      "jerry: you think she'd hit the friendship.\n",
      "\n",
      "jerry: well, what are you gonna do?\n",
      "\n",
      "george: i don't know. you can't stand around.\n",
      "\n",
      "elaine: oh.\n",
      "\n",
      "jerry:(confused) aww.(holds his nose up)\n",
      "\n",
      "kramer: well it's not a date, it was the only issue you've ever seen for yourself, huh?\n",
      "\n",
      "jerry: no, no, i'm afraid he's gonna call you.\n",
      "\n",
      "elaine:(sighs) well, i think it's fantastic.\n",
      "\n",
      "jerry: oh, come on, george.\n",
      "\n",
      "jerry: yeah, i know.\n",
      "\n",
      "george: well you didn't mention to me that i would possibly care enough for that kind of crap.\n",
      "\n",
      "george: well, you know what this means, but it's only used to be an actress.\n",
      "\n",
      "kramer: hey, i know what i do. i'm feelin' kidding. i'm aware of this, it's all white.\n",
      "\n",
      "jerry:(confused) what're you saying?\n",
      "\n",
      "kramer: well, i don't know what it means, but you gotta finish it, it's not yours. it's just a little burning.\n",
      "\n",
      "jerry: oh, i don't wanna go see him.\n",
      "\n",
      "elaine: oh, i think we should do something.\n",
      "\n",
      "jerry: yeah, well, you know, i don't know.\n",
      "\n",
      "george: well, i don't know.\n",
      "\n",
      "elaine:(handing the bottle back) oh, my god!(\n"
     ]
    }
   ],
   "source": [
    "# run the cell multiple times to get different results!\n",
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'newman' # name for starting the script\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(model, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your favorite scripts\n",
    "\n",
    "Once you have a script that you like (or find interesting), save it to a text file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save script to a text file\n",
    "f =  open(\"generated_script_1.txt\",\"w\")\n",
    "f.write(generated_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Not Perfect\n",
    "It's ok if the TV script doesn't make perfect sense. It should look like alternating lines of dialogue, here is one such example of a few generated lines.\n",
    "\n",
    "### Example generated script\n",
    "\n",
    ">jerry: what about me?\n",
    ">\n",
    ">jerry: i don't have to wait.\n",
    ">\n",
    ">kramer:(to the sales table)\n",
    ">\n",
    ">elaine:(to jerry) hey, look at this, i'm a good doctor.\n",
    ">\n",
    ">newman:(to elaine) you think i have no idea of this...\n",
    ">\n",
    ">elaine: oh, you better take the phone, and he was a little nervous.\n",
    ">\n",
    ">kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't.\n",
    ">\n",
    ">jerry: oh, yeah. i don't even know, i know.\n",
    ">\n",
    ">jerry:(to the phone) oh, i know.\n",
    ">\n",
    ">kramer:(laughing) you know...(to jerry) you don't know.\n",
    "\n",
    "You can see that there are multiple characters that say (somewhat) complete sentences, but it doesn't have to be perfect! It takes quite a while to get good results, and often, you'll have to use a smaller vocabulary (and discard uncommon words), or get more data.  The Seinfeld dataset is about 3.4 MB, which is big enough for our purposes; for script generation you'll want more than 1 MB of text, generally. \n",
    "\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save another copy as an HTML file by clicking \"File\" -> \"Download as..\"->\"html\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission. Once you download these files, compress them into one zip file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
